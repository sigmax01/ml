---
title: 判别式模型和生成式模型
comments: true
---

# 判别式模型和生成式模型[^1]

假设我们有训练数据$(X, Y)$, $X$是属性集合, $Y$是训练标记, 这个时候来了一个新的样本$x$, 我们要预测它的类别$y$, 我们最终的目的是要求得最大的条件概率$p(y|x)$, 其中的$y$做为新样本的分类.

如果是判别式模型, 则会根据数据得到分类函数和分界面, 比如说根据SVM模型得到一个分界面, 在这个分类面的一侧, 分类结果是A, 在这个分类面的另一侧, 分类结果是B. 判别式模型就是对这个分类面建模, 学习到不同类别之间的最优边界, 但是它无法反应类A, 或者是类B本身的特性, 它只能告诉我们分类的类别.

如果是生成式模型, 会对每一个类建立一个模型, 比如说类别标签有{🐱, 🐶, 🐷}, 那么首先根据🐱的特征学习出一个🐱的模型, 再根据🐶的特征学习出🐶的模型, 最后根据🐷的特征学习出🐷的特性, 之后分别计算新样本$x$分别跟这三个类别的联合概率$p(x, y)$, 然后根据贝叶斯公式$p(y|x)=\frac{p(x, y)}{p(x)}$分别计算三个$p(y|x)$, 选择这三个类别中最大的作为分类.

下面两图可以更加清晰地看出两个模型之间的区别:

<figure markdown='1'>
![](https://img.ricolxwz.io/60a52a3289e03706a2808f6040120717.avif){width="500"}
</figure>

<figure markdown='1'>
![](https://img.ricolxwz.io/ecbafa552c33e5925b0ff77361ddaad0.avif){width="500"}
</figure>

总结一下, 判别式模型直接学习决策函数或者条件概率, 不能反映训练数据本身的特性, 它查找的是不同类别之间的最优分裂面, 反映的是异类数据之间的差异, 直接面对预测往往学习准确度更高. 生成式模型学习的是联合概率分布, 可以从统计的角度表示分布的情况, 能够反映数据本身的相似度, 它不关心到底划分不同类的边界在哪里.

[^1]: Microstrong. (2019, 八月 25). 机器学习中的判别式模型和生成式模型 [知乎专栏文章]. 人工智能. https://zhuanlan.zhihu.com/p/74586507
