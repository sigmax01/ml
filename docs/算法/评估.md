---
title: 评估
comments: true
---

## 留出验证法

将数据随机分为两个集合: 一个是训练集, 另一个是测试集. 通常是$2/3$的训练集, $1/3$的测试集.

使用训练集构建模型, 使用测试集评估模型. 主要是计算准确度还可以使用其他的表现评估手段.

### 准度

准度表示的是正确分类的比例. 可以在训练集和测试集上计算准度.

- 训练集上计算的准度: 过于乐观, 不能很好的反映泛化性能, 特别是在过拟合的情况下
- 测试集上计算的准度: 用于评估泛化表现

### 验证集

有些时候我们需要第三种集合, 即验证集. 例如, 有一些分类方法, 如决策树, 神经网络有两个阶段:

1. 构建分类器
2. 调教超参数, 测试集是不能用于超参数调教的

所以说, 正确的评估过程分为三步:

1. 训练集: 用于构建分类器
2. 验证集: 用于调教超参数
3. 测试集: 用于评估准度

???+ tip "Tip"

    超参数: 机器学习算法中用于性能调教的参数, 不同于普通的参数, 后者本身就属于模型, 例如线性回归模型中的系数.

    常见的超参数的例子有: K最临近算法中的参数k, 在逻辑回归中的参数lambda, 在神经网络中隐藏层的数量和每一层中的节点数, ...

### 分层

当将数据集随机分为训练集和测试集时, 有时会出现某类别的数据在训练集或者测试集中缺失或者失衡的情况. 比如, 如果某一类别的所有样本都分配到测试集中, 那么模型在训练时将无法学习如何预测这个类别, 因为训练集中没有该类别的样本.

为了解决这个问题, 可以使用分层的方法, 即strratification, 这种方法可以和保留法结合使用. 例如, 如果整个数据集中某个类别的比例为60%, 另一个类比的比例为40%, 那么分层可以确保这个比例在训练集和测试集中都保持一致. 

### 重复留出验证法

可以通过重复留出验证法让其变得更加可靠. 如, 运行以下的方法10次: 从数据集中选出一定比例的数据用于训练, 剩余的用于测试. 10次计算出的准度取平均值就是一个整体的平均准度.

## 交叉验证

