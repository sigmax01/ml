---
title: 评估
comments: true
---

## 留出验证法

将数据随机分为两个集合: 一个是训练集, 另一个是测试集. 通常是$2/3$的训练集, $1/3$的测试集.

使用训练集构建模型, 使用测试集评估模型. 主要是计算准确度还可以使用其他的表现评估手段.

### 准度

准度表示的是正确分类的比例. 可以在训练集和测试集上计算准度.

- 训练集上计算的准度: 过于乐观, 不能很好的反映泛化性能, 特别是在过拟合的情况下
- 测试集上计算的准度: 用于评估泛化表现

### 验证集

有些时候我们需要第三种集合, 即验证集. 例如, 有一些分类方法, 如决策树, 神经网络有两个阶段:

1. 构建分类器
2. 调教超参数, 测试集是不能用于超参数调教的

所以说, 正确的评估过程分为三步:

1. 训练集: 用于构建分类器
2. 验证集: 用于调教超参数
3. 测试集: 用于评估准度

???+ tip "Tip"

    超参数: 机器学习算法中用于性能调教的参数, 不同于普通的参数, 后者本身就属于模型, 例如线性回归模型中的系数.

    常见的超参数的例子有: K最临近算法中的参数k, 在逻辑回归中的参数lambda, 在神经网络中隐藏层的数量和每一层中的节点数, ...

### 分层

当将数据集随机分为训练集和测试集时, 有时会出现某类别的数据在训练集或者测试集中缺失或者失衡的情况. 比如, 如果某一类别的所有样本都分配到测试集中, 那么模型在训练时将无法学习如何预测这个类别, 因为训练集中没有该类别的样本.

为了解决这个问题, 可以使用分层的方法, 即strratification, 这种方法可以和保留法结合使用. 例如, 如果整个数据集中某个类别的比例为60%, 另一个类比的比例为40%, 那么分层可以确保这个比例在训练集和测试集中都保持一致. 

### 重复留出验证法

可以通过重复留出验证法让其变得更加可靠. 如, 运行以下的方法10次: 从数据集中选出一定比例的数据用于训练, 剩余的用于测试. 10次计算出的准度取平均值就是一个整体的平均准度.

## 交叉验证

上面我们讲到了重复留出验证法, 交叉验证其实和这个差不多, 也是将数据划分10次, 但是不同的是不是随机划分的, 而是有规则的划分的. 

交叉验证是将数据集分为多个不重叠的子集(称为"折"), 通常为10折. 在k折交叉验证中, 数据集被分为k个等大小的部分, 每次迭代中使用k-1个部分进行训练, 剩下的一个部分用于测试. 这一过程重复k次, 每次用一个不同的部分作为测试集, 最终的模型性能是k次测试结果的平均值.

### 分层

分层10折交叉验证, 这是机器学习验证的标准方法. 许多的实验都证明选10这个数字能得到最准确的估计, 这只是经验, 没有任何理论证明.

如果能够重复分层交叉验证, 那效果更佳, 如重复分层10折交叉验证, 实际上运行了100次的循环.