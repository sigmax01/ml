---
title: 递归神经网络
comments: true
---

递归神经网络, Recurrent Neural Networks, RNN, 用于处理序列化的数据. 文字或者自然语言就是一种序列化的数据, 段落就是单词的序列, 每个段落可能有不同数量的单词, 每个段落中可能包含有长距离依赖关系的单词, 如`The dog in that house is aggressive"和"The dogs in that house are aggressive"中的🐕和谓语之间的长距离依赖关系. 处理这种类型的数据需要模型能够"记住"之前序列中的某些信息.

## 架构

RNN一次处理序列中的一个元素, 例如一个单词. 举例来说, 句子"The dog in the house is aggreesive"会按照时间顺序分解为: $t$时刻处理"the", $t+1$时刻处理"dog"依次类推. RNN之所以被称为"递归神经网络"是因为它包含反馈连接, 即输出会反馈给输入, 这与前馈神经网络不同, 前馈神经网络是有向无环图, acyclic graph, 而递归神经网络是有向有环图, cyclic graph, 更具体的说, 一个神经元在某个时间点的输出会反馈到下一个时间点的相同神经元中, 因此, RNN具备一定的记忆能力, 可以记住之前的激活状态, 由于RNN能够记住过去的激活状态, 因此它能够捕捉长距离的依赖关系, 这种特性使得RNN特别适合用于处理序列数据, 例如语言模型和时间序列预测.

RNN有不同的架构, 其中包括简单的RNN, 又称为Elman网络和长短期记忆网络, LSTM. 

### 简单RNN

简单RNN含有由$1$个隐藏层构成的前馈神经网络, 这个隐藏层特别的, 含有一个记忆缓存, 会存储隐藏层之前一个时间点的状态. 在每一个时间点, 记忆缓存中的数据会和下一组输入结合作为隐藏层神经元的下一次输入.

<figure markdown='1'>
![](https://img.ricolxwz.io/9af1c54b02f52241514fdb945d00fa2b.png){ loading=lazy width='500' }
</figure>

我们定义如下符号:

- $x_t$: $t$时刻的输入向量
- $h_t$: $t$时刻的