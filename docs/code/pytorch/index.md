---
title: PyTorch
---

# PyTorch[^1]

## å¿«é€Ÿå¼€å§‹

è¿™èŠ‚ä¼šä»‹ç»å‡ ä¸ªåœ¨æœºå™¨å­¦ä¹ ä¸­æ¯”è¾ƒå¸¸ç”¨çš„API.

### åŠ è½½æ•°æ®

åœ¨PyTorchä¸­, `touch.utils.data.Dataset`å’Œ`torch.utils.data.Dataloader`æ˜¯ä¸¤ä¸ªç”¨äºæ•°æ®åŠ è½½å’Œå¤„ç†çš„æ ¸å¿ƒå·¥å…·. `Dataset`å­˜å‚¨æ ·æœ¬åŠå…¶å¯¹åº”çš„æ ‡ç­¾, `Dataloader`åœ¨`Dataset`å‘¨å›´åŒ…è£…ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡.

PyTorchæä¾›å±äºç‰¹å®šé¢†åŸŸçš„åº“, ä¾‹å¦‚TorchText, TorchVisionå’ŒTorchAudio, å®ƒä»¬éƒ½åŒ…å«ä¸€äº›å·²ç»é¢„å®šä¹‰çš„`Dataset`æ•°æ®é›†. ä¾‹å¦‚, `torchvision.datasets`æ¨¡å—åŒ…å«ç”¨äºè®¸å¤šç°å®ä¸–ç•Œè§†è§‰æ•°æ®çš„`Dataset`å¯¹è±¡, ä¾‹å¦‚COCO, CIFAR-10ç­‰. åœ¨æœ¬æ¡ˆä¾‹ä¸­, ä½¿ç”¨FashionMNISTæ•°æ®é›†. æ¯ä¸ªTorchVisionçš„`Dataset`åŒ…å«ä¸¤ä¸ªå‚æ•°: `transform`å’Œ`target_transform`, åˆ†åˆ«ç”¨äºä¿®æ”¹æ ·æœ¬å’Œæ ‡ç­¾.

```py title="è¾“å…¥"
from torchvision import datasets
from torchvision.transforms import ToTensor
# ä»¥FashionMNISTè®­ç»ƒæ•°æ®é›†ä¸ºä¾‹
training_data = datasets.FashionMNIST(
    root="drive/MyDrive/Data/FashionMNIST",
    train=True,
    download=True,
    transform=ToTensor()
)
# ä»¥FashionMNISTæµ‹è¯•æ•°æ®é›†ä¸ºä¾‹
test_data = datasets.FashionMNIST(
    root="drive/MyDrive/Data/FashionMNIST",
    train=False,
    download=False, # ç”±äºåˆšæ‰å·²ç»ä¸‹è½½è¿‡äº†, æ‰€ä»¥è¿™é‡Œè®¾ç½®ä¸ºFalse
    transform=ToTensor()
)
```

``` title="è¾“å‡º"
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.4M/26.4M [00:01<00:00, 20.9MB/s]
Extracting drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 427kB/s]
Extracting drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.42M/4.42M [00:00<00:00, 6.11MB/s]
Extracting drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.15k/5.15k [00:00<00:00, 18.9MB/s]
Extracting drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to drive/MyDrive/Data/FashionMNIST/FashionMNIST/raw
```

??? note "`root`, `download`, `transform`æ˜¯å•¥"

    å…¶ä¸­, `root`æŒ‡å®šæ•°æ®é›†ä¸‹è½½å’Œä¿å­˜çš„æ ¹ç›®å½•è·¯å¾„, ä¾‹å¦‚, è®¾ç½®`root="data"`, æ•°æ®é›†ä¼šè¢«ä¸‹è½½åˆ°å½“å‰å·¥ä½œç›®å½•ä¸‹çš„`data`æ–‡ä»¶å¤¹ä¸­. å½“`download=True`çš„æ—¶å€™, å¦‚æœæŒ‡å®šçš„`root`ç›®å½•ä¸‹æ²¡æœ‰æ•°æ®é›†, å°±ä¼šè‡ªåŠ¨ä»ç½‘ä¸Šä¸‹è½½, å¦‚æœå·²ç»ä¸‹è½½è¿‡, å°±ä¸ä¼šå†æ¬¡ä¸‹è½½. `transform`å’Œ`target_transform`æ˜¯å¯é€‰å‚æ•°, ç”¨äºå¯¹æ ·æœ¬å’Œæ ‡ç­¾è¿›è¡Œè½¬æ¢, å¦‚`ToTensor()`ä¼šå°†PILå›¾åƒæˆ–NumPyæ•°ç»„è½¬æ¢ä¸ºå¼ é‡, é™¤äº†`ToTensor()`, è¿˜å¯ä»¥è¿›è¡Œå…¶ä»–è½¬æ¢æ“ä½œ, å¦‚æ ‡å‡†åŒ–, è£å‰ª, è°ƒæ•´å¤§å°ç­‰.

æˆ‘ä»¬å°†`Dataset`ä½œä¸ºå‚æ•°ä¼ é€’ç»™`Datalocader`. è¿™å°†åŒ…è£…æ•°æ®é›†, å¹¶æä¾›å¯¹æ•°æ®é›†çš„è¿­ä»£è®¿é—®. åœ¨è®­ç»ƒæ¨¡å‹æ—¶, æˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨`Dataloader`, å› ä¸ºå®ƒæ”¯æŒè‡ªåŠ¨æ‰¹é‡å¤„ç†, é‡‡æ ·, æ´—ç‰Œå¤šè¿›ç¨‹æ•°æ®åŠ è½½.

```py title="è¾“å…¥"
from torch.utils.data import DataLoader
batch_size = 64
train_dataloader = DataLoader(training_data, batch_size=batch_size)
test_dataloader = DataLoader(test_data, batch_size=batch_size)
for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    break
```

``` title="è¾“å‡º"
Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])
Shape of y: torch.Size([64]) torch.int64
```

??? note "`test_dataloader`æ˜¯å•¥"

    `test_dataloader`æ˜¯ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡. é‡Œé¢åŒ…å«äº†æ•´ä¸ªæµ‹è¯•æ•°æ®é›†, å¹¶å°†å…¶åˆ†æˆäº†å¾ˆå¤šæ‰¹æ¬¡. æ¯æ¬¡è¿­ä»£`test_dataloader`çš„æ—¶å€™, å®ƒä¼šè¿”å›ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®, ç›´åˆ°éå†å®Œæ•´ä¸ªæ•°æ®é›†. æ‰€ä»¥ä¸Šé¢çš„`X`å¯¹åº”çš„æ˜¯ç¬¬ä¸€æ‰¹æ•°æ®, `N`è¡¨ç¤ºçš„æ˜¯æ‰¹æ¬¡å¤§å°, `C`è¡¨ç¤ºçš„æ˜¯é€šé“æ•°, `H`è¡¨ç¤ºçš„æ˜¯å›¾åƒé«˜åº¦, `W`è¡¨ç¤ºçš„æ˜¯å›¾åƒå®½åº¦.

### åˆ›å»ºæ¨¡å‹

åœ¨PyTorchä¸­åˆ›å»ºæ¨¡å‹çš„æ–¹æ³•æ˜¯å†™ä¸€ä¸ªç»§æ‰¿`nn.Module`çš„ç±». åœ¨`__init__`å‡½æ•°ä¸­å®šä¹‰ç½‘ç»œçš„å±‚. ç„¶ååœ¨`forward`å‡½æ•°ä¸­å®šä¹‰æ•°æ®å¦‚ä½•æµç»è¿™äº›å±‚. ä¸ºäº†åŠ é€Ÿæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œ, æœ€å¥½æŠŠæ“ä½œè½¬ç§»åˆ°GPUæˆ–è€…MPSä¸Šé¢.

??? tip "MPSæ˜¯å•¥"

    MPSæ˜¯Metal Performace Shaderçš„ç¼©å†™, æ˜¯ç”±Appleæä¾›çš„ä¸€ç§é«˜æ€§èƒ½å›¾å½¢å’Œè®¡ç®—æ¡†æ¶, å®ƒæ˜¯Metal APIçš„ä¸€éƒ¨åˆ†, ä¸“ä¸ºåŠ é€Ÿå›¾å½¢å¤„ç†å’Œæœºå™¨å­¦ä¹ ä»»åŠ¡è®¾è®¡. å®ƒæä¾›äº†ä¸€ç»„é«˜åº¦ä¼˜åŒ–çš„å›¾å½¢ç€è‰²å™¨, ç”¨äºå¤„ç†è¯¸å¦‚å›¾åƒæ»¤é•œ, å·ç§¯æ“ä½œå’Œå…¶ä»–è®¡ç®—å¯†é›†ä»»åŠ¡.

```py title='è¾“å…¥'
import torch
from torch import nn
# é€‰æ‹©CPU, GPUæˆ–è€…MPSè®¾å¤‡ç”¨äºè®­ç»ƒ
device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)

# å®šä¹‰æ¨¡å‹
class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = NeuralNetwork().to(device) # å°†æ¨¡å‹é€åˆ°GPUä¸Š(åŒ…æ‹¬å…¶åˆå§‹åŒ–çš„å‚æ•°)
print(model)
```

``` title='è¾“å‡º'
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
```

### ä¼˜åŒ–å‚æ•°

ä¸ºäº†è®­ç»ƒæ¨¡å‹, æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªä¼˜åŒ–å™¨.

??? note "ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨"

    ä¼˜åŒ–å™¨, Optimizerå…¶å®å°±æ˜¯æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ ä¸­ç”¨äºè°ƒæ•´æ¨¡å‹å‚æ•°(æƒé‡å’Œåç½®)çš„ç®—æ³•å·¥å…·, ä»¥å‡å°‘æŸå¤±å‡½æ•°çš„å€¼, å®ƒæ˜¯è®­ç»ƒç¥ç»ç½‘ç»œçš„å¿…é¡»ç»„ä»¶, é€šè¿‡åå‘ä¼ æ’­ä¸æ–­è°ƒæ•´å‚æ•°. ä¼˜åŒ–å™¨æ˜¯åŸºäºæ¢¯åº¦ä¸‹é™çš„, å¯ä»¥é€‰æ‹©çš„æ¢¯åº¦ä¸‹é™ç®—æ³•æœ‰GD, SGD, Mini-batch GD(æœ€å¸¸ç”¨). è¿˜å¯ä»¥å¼•å…¥åŠ¨é‡ç³»æ•°, æƒé‡è¡°å‡ç­‰æ¦‚å¿µ.

```py
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # lræ˜¯å­¦ä¹ ç‡
```

å¦‚æœé‡‡ç”¨Mini-batch GDçš„è¯, ç„¶åé€šè¿‡åå‘ä¼ æ’­æ›´æ–°æ¨¡å‹çš„å‚æ•°.

```py
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset) # è¿”å›çš„æ˜¯æ•´ä¸ªæ•°æ®é›†çš„å¤§å°
    model.train() # ä½œç”¨è§ä¸‹æ–¹
    for batch, (X, y) in enumerate(dataloader): # dataloaderä¸€æ¬¡è¿­ä»£ä¼šè¿”å›ä¸€ä¸ªæ‰¹, enumerateçš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ‰¹æ¬¡ç´¢å¼•, ç¬¬äºŒä¸ªå‚æ•°æ˜¯æ‰¹æ¬¡æ•°æ®
        X, y = X.to(device), y.to(device) # å°†æ•°æ®é€åˆ°GPUä¸Š

        # å‰å‘ä¼ æ’­å¹¶è®¡ç®—è¯¯å·®
        pred = model(X)
        loss = loss_fn(pred, y) # å¯è°ƒç”¨å¯¹è±¡

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step() # æ›´æ–°å‚æ•°
        optimizer.zero_grad() # ä½œç”¨è§ä¸‹æ–¹

        if batch % 100 == 0: # æ¯100æ‰¹æ‰‹åŠ¨æ‰“å°ä¸€æ¬¡æŸå¤±å’Œå½“å‰è¿›åº¦(å æ€»ä½“ç™¾åˆ†æ¯”)
            loss, current = loss.item(), (batch + 1) * len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")
```

??? note "`model.train()`çš„ä½œç”¨"

    `model.train()`æ˜¯ä¸€ä¸ªå°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼çš„æ–¹æ³•. è¿™ä¸ªæ˜¯å¿…è¦çš„, å› ä¸ºæŸäº›è¡Œä¸ºåœ¨è®­ç»ƒå’Œè¯„ä¼°æœŸé—´æ˜¯ä¸åŒçš„. ä¾‹å¦‚Dropoutå’ŒBN. Dropoutåœ¨è®­ç»ƒæ¨¡å¼ä¸‹, ä¼šéšæœºå°†æŸäº›ç¥ç»å…ƒçš„è¾“å‡ºç½®ä¸º0, é˜²æ­¢è¿‡æ‹Ÿåˆ, è€Œæµ‹è¯•æ¨¡å¼ä¸‹, ä¸ä¼šä¸¢å¼ƒä»»ä½•ç¥ç»å…ƒ; BNåœ¨è®­ç»ƒæ¨¡å¼ä¸‹, ä¼šå¯¹å½“å‰æ‰¹æ¬¡çš„æ•°æ®å½’ä¸€åŒ–, åœ¨è¯„ä¼°æ¨¡å¼ä¸‹, BNå¯¹å…¨å±€çš„æ•°æ®å½’ä¸€åŒ–, è¿™ä¸ªå’ŒLNæ˜¯ä¸ä¸€æ ·çš„, LNåœ¨è®­ç»ƒå’Œæµ‹è¯•æ¨¡å¼ä¸‹æ²¡æœ‰ä¸åŒ. åŒç†, å¯ä»¥ç”¨`model.eval()`å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼.

??? note "`optimizer.zero_grad()`çš„ä½œç”¨"

    è¿™ç”¨äºæ¸…é™¤æ¢¯åº¦(å°†å‚æ•°çš„æ¢¯åº¦è®¾ç½®ä¸º0). è¿™æ˜¯ç”±äºåœ¨PyTorché‡Œé¢, æ¢¯åº¦ä¸ä¼šè¢«è‡ªåŠ¨æ¸…é™¤, éœ€è¦æ‰‹åŠ¨æ¸…é™¤. å¦‚æœä¸æ¸…é™¤æ¢¯åº¦, ä¼šå¯¼è‡´æ–°çš„æ¢¯åº¦å åŠ åˆ°ä¹‹å‰çš„æ¢¯åº¦ä¸Š, è¿™æ˜¯å®ƒçš„è®¾è®¡ç‰¹å¾, ç›®çš„æ˜¯ä¸ºäº†æ”¯æŒæŸäº›é«˜çº§åŠŸèƒ½, å¦‚ç´¯ç§¯æ¢¯åº¦.

??? note "`.item()`çš„ä½œç”¨"

    åœ¨PyTorchä¸­, ç»å¸¸ä¼šçœ‹è§`.item()`. è¿™ä¸ªçš„ä½œç”¨æ˜¯å°†æ ‡é‡tensor, ä¹Ÿå°±æ˜¯åªåŒ…å«ä¸€ä¸ªå€¼çš„å¼ é‡å˜æˆä¸€ä¸ªæ™®é€šçš„Pythonæ ‡é‡.

??? note "å¯è°ƒç”¨å¯¹è±¡"

    åœ¨Pythonä¸­, å¦‚æœä¸€ä¸ªå¯¹è±¡å®šä¹‰äº†`__call__`æ–¹æ³•, åˆ™å¯ä»¥åƒè°ƒç”¨å‡½æ•°ä¸€æ ·è°ƒç”¨è¿™ä¸ªå¯¹è±¡, è¿™å°±æ˜¯æ‰€è°“çš„"å¯è°ƒç”¨å¯¹è±¡". åœ¨ä¸Šé¢çš„ä»£ç ä¸­, `nn.CrossEntropyLoss()`è¿”å›çš„å¯¹è±¡ä¸­å°±å®šä¹‰äº†`__call__`æ–¹æ³•, å› æ­¤å¯ä»¥ç›´æ¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨å¯¹è±¡.

    ```py
    loss = loss_fn(pred, y)
    ```

    ä¸Šè¿°ä»£ç ç­‰ä»·äº:

    ```py
    loss = loss_fn.__call__(pred, y)
    ```

??? note "æ¨¡å‹å’Œæ•°æ®åœ¨è®¾å¤‡ä¸Šçš„åˆ†ç¦»æ€§"

    PyTorchä¸ºäº†æé«˜çµæ´»æ€§å’Œæ¨¡å—åŒ–, å¯ä»¥é€‰æ‹©å°†æ¨¡å‹(åŒ…æ‹¬å…¶å‚æ•°)å’Œè®­ç»ƒ/æµ‹è¯•æ•°æ®å­˜æ”¾åœ¨ä¸åŒçš„è®¾å¤‡ä¸Š. è¿™æ˜¯å› ä¸º, åœ¨å¾ˆå¤šæ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­, æ•°æ®é¢„å¤„ç†(å¦‚data augementation, æ–‡æœ¬ç¼–ç , æ•°æ®åŠ è½½)é€šå¸¸æ›´é€‚åˆåœ¨CPUä¸Šæ‰§è¡Œ, å› ä¸ºè¿™äº›æ“ä½œå¯¹GPUçš„é«˜å¹¶è¡Œè®¡ç®—èƒ½åŠ›åˆ©ç”¨ç‡ä¸é«˜. è¿˜æœ‰åŸå› æ˜¯GPUçš„æ˜¾å­˜å®¹é‡å¾€å¾€ä¼šä¸å¤Ÿ, éœ€è¦å¤„ç†å¤§é‡æ•°æ®çš„æ—¶å€™, éœ€è¦å°†æ•°æ®åˆ†æ‰¹åŠ è½½åˆ°GPU, åˆ©ç”¨æ™®é€šå†…å­˜ä½œä¸ºç¼“å†²åŒº. ä½†æ˜¯çœŸæ­£æ­£åœ¨å‚ä¸è®¡ç®—çš„æ•°æ®å’Œæ¨¡å‹éƒ½å¿…é¡»åœ¨åŒä¸€ä¸ªè®¾å¤‡, è¦ä¸æ˜¯GPU, è¦ä¸æ˜¯CPU.

    åœ¨ä¸Šé¢çš„ä»£ç ä¸­, æˆ‘ä»¬é¦–å…ˆå°†æ¨¡å‹æ”¾åˆ°äº†GPUä¸­: `NeuralNetwork().to(device)`. ç„¶å, åˆ†æ‰¹æ¬¡å°†æ•°æ®åŠ è½½åˆ°GPUä¸­: `X, y = X.to(device), y.to(device)`.


åŒæ ·, æˆ‘ä»¬ä¹Ÿæ‹¿æµ‹è¯•é›†æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½.

```py
def test(dataloader, model, loss_fn):
    size = len(dataloader.dataset) # è¿”å›æ•´ä¸ªè®­ç»ƒé›†çš„å¤§å°
    num_batches = len(dataloader) # è¿”å›æ€»çš„æ‰¹æ¬¡æ•°
    model.eval() # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    test_loss, correct = 0, 0
    with torch.no_grad(): # ä½œç”¨è§ä¸‹æ–¹
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)
            pred = model(X)
            test_loss += loss_fn(pred, y).item() # å°†å½“å‰æ‰¹æ¬¡çš„æŸå¤±å€¼, ç´¯åŠ åˆ°test_lossä¸Š
            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # å°†å½“å‰æ‰¹æ¬¡çš„æ­£ç¡®é¢„æµ‹æ•°, ç´¯åŠ åˆ°correctä¸Š
    test_loss /= num_batches # è®¡ç®—å¹³å‡æŸå¤±
    correct /= size # è®¡ç®—å‡†åº¦
    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")
```

??? note "`torch.no_grad()`çš„ä½œç”¨"

    ç”¨äºç¦ç”¨æ¢¯åº¦è®¡ç®—, è¿™æ„å‘³ç€åœ¨è¿™ä¸ªä»£ç å—å†…, ä¸ä¼šè·Ÿè¸ªæ¨¡å‹å‚æ•°çš„æ¢¯åº¦, å› ä¸ºè¿™æ˜¯è¯„ä¼°æ¨¡å¼, æ‰€ä»¥ä¸éœ€è¦æ›´æ–°æ¨¡å‹çš„å‚æ•°. è¿™æ®µä»£ç å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸€èµ·ä½¿ç”¨, ç®€åŒ–è¡¨ç¤º.

??? note "`pred.argmax(1)`çš„ä½œç”¨"

    åœ¨è¿™é‡Œ, `pred`æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(64, 10)çš„tensor. è¡¨ç¤ºè¿™ä¸€æ‰¹ä¸­æ‰€æœ‰å›¾ç‰‡å¯¹åº”10ä¸ªåˆ†ç±»çš„æ¦‚ç‡. `pred.argmax(1)`çš„ä½œç”¨æ˜¯æ²¿ç€`pred`tensorçš„ç¬¬1ä¸ªç»´åº¦æŸ¥æ‰¾æœ€å¤§å€¼å¯¹åº”çš„index, å³åœ¨64å¼ å›¾ç‰‡ä¸­æŸ¥æ‰¾å„è‡ªæ¦‚ç‡æœ€å¤§çš„åˆ†ç±». `pred.argmax(1) == y`å¾—åˆ°çš„åº”è¯¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(64, )çš„tensor, å…¶ä¸­çš„å€¼æ˜¯`True, False`, å°†å…¶è½¬åŒ–ä¸º`True/False`ä¹‹åç»Ÿè®¡ä¸€ä¸‹`True`çš„ä¸ªæ•°, ç„¶åç”¨`.item()`å°†æ ‡é‡tensorè½¬åŒ–ä¸ºPythonæ•°å€¼.

```py title='è¾“å…¥'
epochs = 5
for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    train(train_dataloader, model, loss_fn, optimizer)
    test(test_dataloader, model, loss_fn)
print("Done!")
```

``` title='è¾“å‡º'
Epoch 1
-------------------------------
loss: 2.304085  [   64/60000]
loss: 2.294508  [ 6464/60000]
loss: 2.274109  [12864/60000]
loss: 2.270270  [19264/60000]
loss: 2.250886  [25664/60000]
loss: 2.220479  [32064/60000]
loss: 2.225041  [38464/60000]
loss: 2.189506  [44864/60000]
loss: 2.192357  [51264/60000]
loss: 2.157102  [57664/60000]
Test Error:
 Accuracy: 47.3%, Avg loss: 2.149917

Epoch 2
-------------------------------
loss: 2.157969  [   64/60000]
loss: 2.146327  [ 6464/60000]
loss: 2.088529  [12864/60000]
loss: 2.110613  [19264/60000]
loss: 2.043306  [25664/60000]
loss: 1.994351  [32064/60000]
loss: 2.016328  [38464/60000]
loss: 1.932480  [44864/60000]
loss: 1.945457  [51264/60000]
loss: 1.870950  [57664/60000]
Test Error:
 Accuracy: 54.1%, Avg loss: 1.864029

Epoch 3
-------------------------------
loss: 1.894473  [   64/60000]
loss: 1.860638  [ 6464/60000]
loss: 1.745864  [12864/60000]
loss: 1.795800  [19264/60000]
loss: 1.669494  [25664/60000]
loss: 1.634574  [32064/60000]
loss: 1.653545  [38464/60000]
loss: 1.551876  [44864/60000]
loss: 1.585930  [51264/60000]
loss: 1.479611  [57664/60000]
Test Error:
 Accuracy: 60.3%, Avg loss: 1.494985

Epoch 4
-------------------------------
loss: 1.560271  [   64/60000]
loss: 1.524853  [ 6464/60000]
loss: 1.380546  [12864/60000]
loss: 1.458671  [19264/60000]
loss: 1.330814  [25664/60000]
loss: 1.335623  [32064/60000]
loss: 1.347326  [38464/60000]
loss: 1.269260  [44864/60000]
loss: 1.312450  [51264/60000]
loss: 1.211600  [57664/60000]
Test Error:
 Accuracy: 63.7%, Avg loss: 1.235736

Epoch 5
-------------------------------
loss: 1.311352  [   64/60000]
loss: 1.291073  [ 6464/60000]
loss: 1.130169  [12864/60000]
loss: 1.241175  [19264/60000]
loss: 1.110151  [25664/60000]
loss: 1.140992  [32064/60000]
loss: 1.162442  [38464/60000]
loss: 1.094141  [44864/60000]
loss: 1.142886  [51264/60000]
loss: 1.054473  [57664/60000]
Test Error:
 Accuracy: 65.0%, Avg loss: 1.074178

Done!
```

### ä¿å­˜æ¨¡å‹

ä¸€ç§å¸¸è§çš„ä¿å­˜æ¨¡å‹çš„åšæ³•æ˜¯åºåˆ—åŒ–å†…éƒ¨çŠ¶æ€çš„ç›¸å…³å­—å…¸, internal state dictionary, è¿™ä¸ªå­—å…¸ç”¨äºå­˜å‚¨æ¨¡å‹æˆ–è€…ä¼˜åŒ–å™¨çš„å†…éƒ¨çŠ¶æ€(å¦‚æƒé‡, åç½®, å­¦ä¹ ç‡ç­‰).

```py title='è¾“å…¥'
torch.save(model.state_dict(), "drive/MyDrive/Model/FashionMNIST/model.pth")
print("Saved PyTorch Model State to model.pth")
```

``` title='è¾“å‡º'
Saved PyTorch Model State to model.pth
```

### åŠ è½½æ¨¡å‹

åŠ è½½æ¨¡å‹çš„æ–¹æ³•æ˜¯é‡æ–°åˆ›é€ æ¨¡å‹å¹¶ååºåˆ—åŒ–å¾—åˆ°å†…éƒ¨çŠ¶æ€çš„ç›¸å…³å­—å…¸, ç„¶åç”¨è¿™ä¸ªå­—å…¸å»è¦†ç›–åˆå§‹åŒ–å¥½çš„æ¨¡å‹.

```py title='è¾“å…¥'
model = NeuralNetwork().to(device)
model.load_state_dict(torch.load("drive/MyDrive/Model/FashionMNIST/model.pth", weights_only=True))
```

``` title='è¾“å‡º'
<All keys matched successfully>
```

ç„¶åè¿™ä¸ªæ¨¡å‹å°±èƒ½å¤Ÿç”¨æ¥é¢„æµ‹äº†.

```py title='è¾“å…¥'
classes = [
    "T-shirt/top",
    "Trouser",
    "Pullover",
    "Dress",
    "Coat",
    "Sandal",
    "Shirt",
    "Sneaker",
    "Bag",
    "Ankle boot",
]

model.eval()
x, y = test_data[0][0], test_data[0][1] # åªæ‹¿å‡ºç¬¬ä¸€ä¸ªæ ·æœ¬å‡ºæ¥
with torch.no_grad():
    x = x.to(device)
    pred = model(x)
    predicted, actual = classes[pred[0].argmax(0)], classes[y]
    print(f'Predicted: "{predicted}", Actual: "{actual}"')
```

``` title='è¾“å‡º'
Predicted: "Ankle boot", Actual: "Ankle boot"
```

???+ note "`test_data[0][0]`çš„å«ä¹‰"

    `training_data`æˆ–è€…æ˜¯`test_data`æ˜¯æˆ‘ä»¬çš„æ•°æ®é›†, å…¶ä¸­ç¬¬ä¸€ä¸ªindexè¡¨ç¤ºçš„æ˜¯ç¬¬å‡ ä¸ªæ ·æœ¬, ç¬¬äºŒä¸ªindexè¡¨ç¤ºå½“å‰è¿™ä¸ªæ ·æœ¬çš„ç‰¹å¾è¿˜æ˜¯æ ‡ç­¾. å¦‚`test[0][0]`è¡¨ç¤ºçš„æ˜¯ç¬¬ä¸€å¼ ç…§ç‰‡çš„ç‰¹å¾çŸ©é˜µ.

## Tensors

Tensoræ˜¯ä¸€ç§å’Œæ•°ç»„å’ŒçŸ©é˜µå¾ˆåƒçš„æ•°æ®ç»“æ„, åœ¨PyTorché‡Œé¢, ä½¿ç”¨tensorç¼–ç æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡º, åŒ…æ‹¬æ¨¡å‹çš„å‚æ•°. tensorå’Œnumpyçš„ndæ•°ç»„å¾ˆåƒ, åªæ˜¯tensorå¯ä»¥è·‘åœ¨GPUå’Œå…¶ä»–ç¡¬ä»¶åŠ é€Ÿå™¨ä¸Š. å®é™…ä¸Š, numpyçš„æ•°ç»„å’Œtensorå¯ä»¥å…±ç”¨ä¸€å—å†…å­˜, è€Œä¸ç”¨å¤åˆ¶æ•°æ®. Tensorä¹Ÿå¯¹è‡ªåŠ¨å¾®åˆ†è¿›è¡Œäº†ä¼˜åŒ–.

### åˆå§‹åŒ–Tensor

å¯ä»¥é€šç”¨å¤šç§æ–¹å¼åˆå§‹åŒ–tensor.

1. ç›´æ¥ä»æ•°æ®åˆå§‹åŒ–, ä¼šè‡ªåŠ¨æ¨æ–­æ•°æ®ç±»å‹

    ```py
    data = [[1, 2], [3, 4]]
    x_data = torch.tensor(data)
    ```

2. ä»NumPyæ•°ç»„åˆå§‹åŒ–

    ```py
    np_array = np.array(data)
    x_np = torch.from_numpy(np_array)
    ```

3. ä»å¦ä¸€ä¸ªtensoråˆå§‹åŒ–, ä¼šä¿ç•™å¦ä¸€ä¸ªtensorçš„å±æ€§(å½¢çŠ¶, ç±»å‹), é™¤éç‰¹åˆ«è¦†ç›–

    ```py title='è¾“å…¥'
    x_ones = torch.ones_like(x_data) # ä¿ç•™x_dataçš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹
    print(f"Ones Tensor: \n {x_ones} \n")
    x_rand = torch.rand_like(x_data, dtype=torch.float) # ä¿ç•™x_dataçš„å½¢çŠ¶, ä½†æ˜¯æ•°æ®ç±»å‹æ˜¯float
    print(f"Random Tensor: \n {x_rand} \n")
    ```

    ``` title='è¾“å‡º'
    Ones Tensor:
     tensor([[1, 1],
            [1, 1]])

    Random Tensor:
     tensor([[0.7053, 0.3019],
            [0.6510, 0.0095]])
    ```

4. å¡«å……éšæœºæˆ–è€…å¸¸é‡

    ```py title='è¾“å…¥'
    shape = (2,3,)
    rand_tensor = torch.rand(shape)
    ones_tensor = torch.ones(shape)
    zeros_tensor = torch.zeros(shape)

    print(f"Random Tensor: \n {rand_tensor} \n")
    print(f"Ones Tensor: \n {ones_tensor} \n")
    print(f"Zeros Tensor: \n {zeros_tensor}")
    ```

    ``` title='è¾“å‡º'
    Random Tensor:
     tensor([[0.0596, 0.0417, 0.1678],
            [0.9480, 0.0777, 0.4989]])

    Ones Tensor:
     tensor([[1., 1., 1.],
            [1., 1., 1.]])

    Zeros Tensor:
     tensor([[0., 0., 0.],
            [0., 0., 0.]])
    ```

### Tensorçš„å±æ€§

Tensorå±æ€§ä¸»è¦æè¿°äº†å®ƒä»¬çš„å½¢çŠ¶, æ•°æ®ç±»å‹, ä»¥åŠå®ƒä»¬å­˜å‚¨çš„è®¾å¤‡.

```py title='è¾“å…¥'
tensor = torch.rand(3,4)

print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
print(f"Device tensor is stored on: {tensor.device}")
```

``` title='è¾“å‡º'
Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu
```

### Tensorçš„æ“ä½œ

è¶…è¿‡100ç§tensorçš„æ“ä½œ, åŒ…æ‹¬ç®—æœ¯è¿ç®—, çŸ©é˜µä¹˜æ³•(è½¬ç½®, åˆ‡ç‰‡, ç´¢å¼•). å…·ä½“å¯ä»¥è§[è¿™é‡Œ](https://pytorch.org/docs/stable/torch.html).

è¿™äº›æ“ä½œéƒ½èƒ½åœ¨GPUä¸Šè¿è¡Œ(é€šå¸¸æ¯”CPUå¿«å¾ˆå¤š), é»˜è®¤æƒ…å†µä¸‹, tensorä¸Šåˆ›å»ºåœ¨CPUä¸Šé¢çš„. æˆ‘ä»¬éœ€è¦ç‰¹åˆ«çš„ä½¿ç”¨`.to`å‡½æ•°å°†tensorè½¬ç§»åˆ°GPUä¸Šé¢. ä½†æ˜¯è®°ä½, åœ¨è®¾å¤‡ä¹‹é—´æ‹·è´æ•°æ®çš„æˆæœ¬æ˜¯å¾ˆé«˜çš„.

```py
# å¦‚æœåœ¨GPUå­˜åœ¨çš„æƒ…å†µä¸‹, å°†tensorè½¬ç§»åˆ°ä¸Šé¢
if torch.cuda.is_available():
    tensor = tensor.to("cuda")
```

ä¸‹é¢åˆ—ä¸¾ä¸€äº›å¸¸è§çš„æ“ä½œAPI.

1. ä¸NumPyç±»ä¼¼çš„ç´¢å¼•å’Œåˆ‡ç‰‡

    ```py title='è¾“å…¥'
    tensor = torch.ones(4, 4)
    print(f"First row: {tensor[0]}")
    print(f"First column: {tensor[:, 0]}")
    print(f"Last column: {tensor[..., -1]}")
    tensor[:,1] = 0
    print(tensor)
    ```

    ``` title='è¾“å‡º'
    First row: tensor([1., 1., 1., 1.])
    First column: tensor([1., 1., 1., 1.])
    Last column: tensor([1., 1., 1., 1.])
    tensor([[1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.]])
    ```

2. èšåˆtensors

    ```py title='è¾“å…¥'
    t1 = torch.cat([tensor, tensor, tensor], dim=1)
    print(t1)
    ```

    ``` title='è¾“å‡º'
    tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])
    ```

    ??? note "è¿™é‡Œçš„`dim`çš„ä½œç”¨"

        è¿™é‡Œçš„`dim=1`çš„æŒ‡çš„æ˜¯æ²¿ç€åˆ—çš„æ–¹å‘èšåˆ.

3. ç®—æœ¯æ“ä½œ

    ```py title='è¾“å…¥'
    # @ä¼šè¿›è¡ŒçŸ©é˜µä¹˜æ³•, ä¸‹é¢y1, y2, y3çš„æœ€ç»ˆç»“æœæ˜¯ä¸€æ ·çš„
    # tensor.Tè¿”å›çš„æ˜¯tensorè¿™ä¸ªå˜é‡ä¸­ä¿å­˜çš„tensorçš„è½¬ç½®
    y1 = tensor @ tensor.T
    y2 = tensor.matmul(tensor.T)
    y3 = torch.rand_like(y1) # è¿™ä¸ªæ˜¯ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„å½¢çŠ¶å’Œy1ç›¸åŒçš„çŸ©é˜µy3
    torch.matmul(tensor, tensor.T, out=y3)

    # *ä¼šè¿›è¡Œå¯¹åº”å…ƒç´ çš„çŸ©é˜µä¹˜æ³•
    z1 = tensor * tensor
    z2 = tensor.mul(tensor)
    z3 = torch.rand_like(tensor)
    torch.mul(tensor, tensor, out=z3)
    ```

4. æ ‡é‡tensor

    å¦‚æœä½ æƒ³è¦ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensor, ä¾‹å¦‚å°†tensorä¸­çš„å…ƒç´ aggregateä¸€ä¸‹ç„¶åä½¿ç”¨`.item()`è½¬åŒ–æˆPythonçš„æ•°å€¼å˜é‡.

    ```py title='è¾“å…¥'
    agg = tensor.sum()
    agg_item = agg.item()
    print(agg_item, type(agg_item))
    ```

    ``` title='è¾“å‡º'
    12.0 <class 'float'>
    ```

5. åŸåœ°æ“ä½œ

    åˆå«åšin-place operation, æŒ‡çš„æ˜¯ç›´æ¥åœ¨åŸå§‹æ•°æ®ä¸Šè¿›è¡Œä¿®æ”¹, è€Œä¸æ˜¯åˆ›å»ºæ–°çš„å‰¯æœ¬è¿›è¡Œå·¥ä½œ, åœ¨PyTorchä¸­, åŸåœ°æ“ä½œé€šå¸¸ä»¥ä¸‹åˆ’çº¿`_`ç»“å°¾.

    ```py title='è¾“å…¥'
    print(f"{tensor} \n")
    tensor.add_(5)
    print(tensor)
    ```

    ``` title='è¾“å‡º'
    tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.]])

    tensor([[6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.]])
    ```

    ??? warning "å°½é‡ä¸è¦ä½¿ç”¨åŸåœ°æ“ä½œ"

        åŸåœ°æ“ä½œä¼šæ”¹å˜tensorçš„çŠ¶æ€, å¯èƒ½ä¼šå½±å“åˆ°å…¶ä»–å¼•ç”¨è¯¥tensorçš„ä»£ç , è€Œä¸”è¿˜å¯èƒ½å½±å“è‡ªåŠ¨æ±‚å¯¼.

### å’ŒNumPyçš„è”ç³»

åœ¨CPUä¸Šçš„tensorå’ŒNumPyçš„æ•°ç»„å¯ä»¥å…±äº«å®ƒä»¬çš„å†…å­˜ç©ºé—´, æ”¹å˜ä¸€ä¸ªçš„åŒæ—¶ä¼šæ”¹å˜å¦ä¸€ä¸ª.

1. Tensoråˆ°NumPyæ•°ç»„

    ```py title='è¾“å…¥'
    t = torch.ones(5)
    print(f"t: {t}")
    n = t.numpy()
    print(f"n: {n}")
    ```

    ``` title='è¾“å‡º'
    t: tensor([1., 1., 1., 1., 1.])
    n: [1. 1. 1. 1. 1.]
    ```

    å¯¹äºtensorçš„ä¿®æ”¹ä¼šæ”¹å˜NumPyæ•°ç»„.

    ```py title='è¾“å…¥'
    t.add_(1)
    print(f"t: {t}")
    print(f"n: {n}")
    ```

    ``` title='è¾“å‡º'
    t: tensor([2., 2., 2., 2., 2.])
    n: [2. 2. 2. 2. 2.]
    ```

2. NumPyæ•°ç»„åˆ°Tensor

    ```py title='è¾“å…¥'
    n = np.ones(5)
    t = torch.from_numpy(n)
    ```

    æ”¹å˜NumPyæ•°ç»„ä¼šåæ˜ åœ¨tensorä¸­.

    ```py title='è¾“å…¥'
    np.add(n, 1, out=n)
    print(f"t: {t}")
    print(f"n: {n}")
    ```

    ``` title='è¾“å‡º'
    t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
    n: [2. 2. 2. 2. 2.]
    ```

## Datasets & DataLoaders

é¢„å¤„ç†æ ·æœ¬çš„ä»£ç å¯èƒ½ä¼šå˜å¾—éå¸¸ä¹±å¹¶ä¸”éš¾ä»¥ç»´æŠ¤, æˆ‘ä»¬å¸Œæœ›æ•°æ®é›†ä»£ç èƒ½å¤Ÿå’Œæ¨¡å‹è®­ç»ƒä»£ç è§£è€¦ä»¥å®ç°æ›´å¥½åœ°å¯è¯»æ€§å’Œæ¨¡å—åŒ–. PyTorchæä¾›ä¸¤ç§é¢„å®šä¹‰çš„ç±»`torch.utils.data.DataLoader`å’Œ`torch.utils.data.Dataset`, è¿™ä¸¤ä¸ªç±»å…è®¸æˆ‘ä»¬ä½¿ç”¨é¢„å®šä¹‰çš„æ•°æ®é›†(å¦‚CIFAR-10)å’Œè‡ªå·±çš„æ•°æ®é›†. `Dataset`å­˜å‚¨çš„æ˜¯æ ·æœ¬å’Œå¯¹åº”çš„æ ‡ç­¾, `DataLoader`åœ¨è¿™ä¸ªåŸºç¡€ä¸ŠæŠŠ`Dataset`åŒ…è£…æˆä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡, ä»¥ä¾¿è½»æ¾è®¿é—®æ ·æœ¬.

PyTorchæä¾›çš„ä¸€äº›é¢„å®šä¹‰çš„æ•°æ®é›†å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°: [å›¾åƒæ•°æ®é›†](https://pytorch.org/vision/stable/datasets.html), [æ–‡æœ¬æ•°æ®é›†](https://pytorch.org/text/stable/datasets.html), [éŸ³é¢‘æ•°æ®é›†](https://pytorch.org/audio/stable/datasets.html)

### åŠ è½½æ•°æ®é›†

ä¸‹é¢æ˜¯ä¸€ä¸ªä»TorchVisionå¯¼å…¥Fashion-MNISTæ•°æ®é›†çš„æ–¹æ³•. Fashion-MNISTæ˜¯ä¸€ä¸ªæ¥æºäºZalandoå…¬å¸çš„æ—¶å°šå•†å“å›¾åƒæ•°æ®é›†, åŒ…å«70000å¼ 28*28åƒç´ çš„ç°åº¦å›¾åƒ, å…¶ä¸­60000å¼ ç”¨äºè®­ç»ƒ, 10000å¼ ç”¨äºæµ‹è¯•, è¯¥æ•°æ®é›†åˆ†ä¸º10ä¸ªç±»åˆ«, åŒ…æ‹¬Tæ¡–/ä¸Šè¡£, è£¤å­, è£™å­, å¤–å¥—, å‡‰é‹, è¿åŠ¨é‹, åŒ…, é•¿è¢œ, è¡¬è¡«å’Œé«˜è·Ÿé‹ç­‰.

æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹çš„å‚æ•°åŠ è½½FashionMNISTæ•°æ®é›†.

- `root`: æ˜¯è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®ä¿å­˜çš„è·¯å¾„
- `train`: å£°æ˜æ˜¯è®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†
- `download=True`: ä»ç½‘ç»œä¸‹è½½æ•°æ®é›†å¦‚æœåœ¨`root`ä¸‹æ²¡æœ‰æ•°æ®é›†çš„è¯
- `transform`å’Œ`target_transform`: å®šä¹‰ç‰¹å¾å’Œæ ‡ç­¾çš„è½¬æ¢å‡½æ•°

```py title='è¾“å…¥'
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt


training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor()
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor()
)
```

``` title='è¾“å‡º'
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz

  0%|          | 0.00/26.4M [00:00<?, ?B/s]
  0%|          | 65.5k/26.4M [00:00<01:12, 361kB/s]
  1%|          | 229k/26.4M [00:00<00:38, 679kB/s]
  3%|3         | 885k/26.4M [00:00<00:10, 2.45MB/s]
  7%|7         | 1.90M/26.4M [00:00<00:05, 4.28MB/s]
 15%|#4        | 3.83M/26.4M [00:00<00:02, 8.19MB/s]
 37%|###7      | 9.80M/26.4M [00:00<00:00, 21.8MB/s]
 50%|####9     | 13.2M/26.4M [00:00<00:00, 22.6MB/s]
 62%|######1   | 16.3M/26.4M [00:01<00:00, 24.8MB/s]
 72%|#######2  | 19.1M/26.4M [00:01<00:00, 25.6MB/s]
 92%|#########2| 24.4M/26.4M [00:01<00:00, 33.1MB/s]
100%|##########| 26.4M/26.4M [00:01<00:00, 19.3MB/s]
Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz

  0%|          | 0.00/29.5k [00:00<?, ?B/s]
100%|##########| 29.5k/29.5k [00:00<00:00, 325kB/s]
Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz

  0%|          | 0.00/4.42M [00:00<?, ?B/s]
  1%|1         | 65.5k/4.42M [00:00<00:12, 359kB/s]
  4%|4         | 197k/4.42M [00:00<00:05, 725kB/s]
 10%|#         | 459k/4.42M [00:00<00:03, 1.17MB/s]
 38%|###7      | 1.67M/4.42M [00:00<00:00, 4.28MB/s]
 83%|########2 | 3.67M/4.42M [00:00<00:00, 7.57MB/s]
100%|##########| 4.42M/4.42M [00:00<00:00, 6.02MB/s]
Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz

  0%|          | 0.00/5.15k [00:00<?, ?B/s]
100%|##########| 5.15k/5.15k [00:00<00:00, 38.2MB/s]
Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw
```

### å¯è§†åŒ–æ•°æ®é›†

æˆ‘ä»¬å¯ä»¥å¯¹`Datasets`å¯¹è±¡è¿›è¡Œç´¢å¼•, å¦‚`training_data[index]`, è¿™è¿”å›çš„æ˜¯æ•°æ®é›†çš„ç¬¬`index`ä¸ªæ ·æœ¬(åŒ…æ‹¬ç‰¹å¾å’Œæ ‡ç­¾, åˆ†åˆ«æ˜¯è¿”å›çš„å…ƒç¥–çš„ç¬¬ä¸€ä¸ªå…ƒç´ å’Œç¬¬äºŒä¸ªå…ƒç´ ). ä½¿ç”¨matplotlibå¯ä»¥å¯¹ä¸€äº›æ ·æœ¬è¿›è¡Œå¯è§†åŒ–æ“ä½œ.

```py title='è¾“å…¥'
labels_map = {
    0: "T-Shirt",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot",
}
figure = plt.figure(figsize=(8, 8))
cols, rows = 3, 3
for i in range(1, cols * rows + 1):
    sample_idx = torch.randint(len(training_data), size=(1,)).item() # è¿™é‡Œçš„training_dataæ˜¯ä¸€ä¸ªå«æœ‰60000ä¸ªå…ƒç´ çš„å¯¹è±¡, å¯ä»¥åƒè®¿é—®åˆ—è¡¨ä¸€æ ·è®¿é—®å®ƒ, éšæœºä»é‡Œé¢é€‰æ‹©ä¸€ä¸ªæ ·æœ¬, ç„¶åä½¿ç”¨.item()å°†æ ‡é‡tensorè½¬åŒ–ä¸ºPythonæ•°å€¼
    img, label = training_data[sample_idx] # åè€…è¿”å›çš„æ˜¯ä¸€ä¸ªå…ƒç¥–, ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç‰¹å¾, ç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ ‡ç­¾
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis("off")
    plt.imshow(img.squeeze(), cmap="gray")
plt.show()
```

<figure markdown='1'>
![](https://img.ricolxwz.io/085abdcf90f7eb7f63be72b28979026e.png){ loading=lazy width='500' }
</figure>

### åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†

ä¸€ä¸ªè‡ªå®šä¹‰çš„æ•°æ®é›†å¿…é¡»å®ç°ä»¥ä¸‹ä¸‰ä¸ªå‡½æ•°, `__init__`, `__len__`å’Œ`__getitem__`. ä¸‹é¢æœ‰ä¸€ä¸ªä¾‹å­, å…¶ä¸­, å›¾ç‰‡å­˜å‚¨åœ¨ç›®å½•`img_dir`ä¸­, å®ƒä»¬çš„æ ‡ç­¾å­˜å‚¨åœ¨ä¸€ä¸ªåˆ†å¼€çš„CSVæ–‡ä»¶`annotations_file`ä¸­.

```py
import os
import pandas as pd
from torchvision.io import read_image

class CustomImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) # ä»img_labelsä¸­æå–ç¬¬idxè¡Œçš„ç¬¬ä¸€åˆ—å†…å®¹, ç„¶åå’Œimg_diræ‹¼æ¥æˆå®Œæ•´çš„è·¯å¾„
        image = read_image(img_path)
        label = self.img_labels.iloc[idx, 1]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label
```

??? note "`annotations_file`æ–‡ä»¶æ ·å­"

    è¿™ä¸ªcsvæ–‡ä»¶é•¿å¾—åƒè¿™æ ·:

    ```csv
    tshirt1.jpg, 0
    tshirt2.jpg, 0
    ......
    ankleboot999.jpg, 9
    ```

### å‡†å¤‡è®­ç»ƒæ•°æ®

æˆ‘ä»¬å¯ä»¥é€šè¿‡`Dataset`å¯¹è±¡ä¸€ä¸ªä¸€ä¸ªå–å‡ºæ•°æ®é›†çš„æ ·æœ¬. ä½†æ˜¯, åœ¨è®­ç»ƒæ¨¡å‹çš„æ—¶å€™, æˆ‘ä»¬é€šå¸¸å¸Œæœ›è¿›è¡Œmini-batch GD, åœ¨æ¯ä¸ªepochå¼€å§‹ä¹‹å‰éƒ½é‡æ–°æ’åˆ—æ•°æ®, ç„¶åæ ¹æ®æ‰“ä¹±åçš„é¡ºåºç”Ÿæˆmini-batchä¾›æ¨¡å‹è®­ç»ƒ, ä»¥å‡å°‘è¿‡æ‹Ÿåˆ, å¹¶ä½¿ç”¨Pythonçš„å¤šè¿›ç¨‹åº“`multiprocessing`æ¥åŠ é€Ÿæ•°æ®çš„å–å›.

`DataLoader`å°±æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå®ç°ä¸Šè¿°åŠŸèƒ½çš„ç®€å•API.

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)
```

### éå†å¯è¿­ä»£å¯¹è±¡

æˆ‘ä»¬å·²ç»æŠŠæ•°æ®é›†åŒ…è£…ä¸ºä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡. ä¸‹åˆ—çš„æ¯ä¸€æ¬¡è¿­ä»£éƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„`train_features`å’Œ`train_labels`, æ¯ä¸ªbatchçš„å¤§å°ä¸º64. ç”±äºæˆ‘ä»¬å£°æ˜äº†`shuffle=True`, æ‰€ä»¥æˆ‘ä»¬éå†å®Œæ‰€æœ‰batchä¹‹åä¼šæ‰“ä¹±æ‰€æœ‰çš„æ•°æ®.

```py title='è¾“å…¥'
train_features, train_labels = next(iter(train_dataloader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {label}")
```

<figure markdown='1'>
  ![](https://img.ricolxwz.io/c0251616f9dcfd140eda0ec82b82eba5.png){ loading=lazy width='500' }
</figure>

``` title='è¾“å‡º'
Feature batch shape: torch.Size([64, 1, 28, 28])
Labels batch shape: torch.Size([64])
Label: 5
```

## è½¬æ¢

æ•°æ®æœ‰å¾ˆå¤§æ¦‚ç‡ä¸æ˜¯ç”¨äºæœºå™¨å­¦ä¹ è¾“å…¥çš„æœ€ç»ˆçŠ¶æ€, æ‰€ä»¥è¦ä½¿ç”¨è½¬æ¢(transform)å¯¹æ•°æ®è¿›è¡Œä¸€äº›ä¿®æ”¹ä½¿å…¶é€‚åˆè®­ç»ƒ.

æ‰€æœ‰çš„TorchVisionæ•°æ®åº“éƒ½æœ‰ä¸¤ä¸ªå‚æ•°, `transform`ç”¨äºä¿®æ”¹ç‰¹å¾, `target_transform`ç”¨äºä¿®æ”¹æ ‡ç­¾, å®ƒä»¬æ¥å—çš„æ˜¯åŒ…å«é€»è¾‘çš„å¯è°ƒç”¨å¯¹è±¡. `torchvision.transforms`æä¾›äº†ä¸€äº›ç»å¸¸ä½¿ç”¨çš„è½¬æ¢å‡½æ•°.

FashionMNISTçš„æ•°æ®ç‰¹å¾æ˜¯PILæ ¼å¼çš„, æ ‡ç­¾æ˜¯int. ä¸ºäº†è®­ç»ƒ, æˆ‘ä»¬éœ€è¦ç‰¹å¾æ˜¯tensor, æ ‡ç­¾æ˜¯one-hotç¼–ç çš„tensor, ä¸ºæ­¤, æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`ToTensor`å’Œ`Lambda`.

```py title='è¾“å…¥'
import torch
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda

ds = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor(),
    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))
)
```

``` title='è¾“å‡º'
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz

  0%|          | 0.00/26.4M [00:00<?, ?B/s]
  0%|          | 65.5k/26.4M [00:00<01:14, 354kB/s]
  1%|          | 197k/26.4M [00:00<00:36, 728kB/s]
  2%|1         | 492k/26.4M [00:00<00:21, 1.23MB/s]
  6%|5         | 1.57M/26.4M [00:00<00:06, 3.97MB/s]
 15%|#4        | 3.83M/26.4M [00:00<00:02, 7.89MB/s]
 31%|###1      | 8.19M/26.4M [00:00<00:01, 17.1MB/s]
 43%|####3     | 11.4M/26.4M [00:00<00:00, 21.1MB/s]
 52%|#####2    | 13.8M/26.4M [00:01<00:00, 21.9MB/s]
 61%|######1   | 16.2M/26.4M [00:01<00:00, 20.6MB/s]
 71%|#######1  | 18.8M/26.4M [00:01<00:00, 22.0MB/s]
 89%|########9 | 23.6M/26.4M [00:01<00:00, 29.1MB/s]
100%|##########| 26.4M/26.4M [00:01<00:00, 17.8MB/s]
Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz

  0%|          | 0.00/29.5k [00:00<?, ?B/s]
100%|##########| 29.5k/29.5k [00:00<00:00, 326kB/s]
Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz

  0%|          | 0.00/4.42M [00:00<?, ?B/s]
  1%|1         | 65.5k/4.42M [00:00<00:12, 361kB/s]
  5%|5         | 229k/4.42M [00:00<00:06, 682kB/s]
 20%|##        | 885k/4.42M [00:00<00:01, 2.54MB/s]
 44%|####3     | 1.93M/4.42M [00:00<00:00, 4.11MB/s]
100%|##########| 4.42M/4.42M [00:00<00:00, 6.09MB/s]
Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz

  0%|          | 0.00/5.15k [00:00<?, ?B/s]
100%|##########| 5.15k/5.15k [00:00<00:00, 38.0MB/s]
Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw
```

??? note "`ToTensor()`çš„ä½œç”¨"

    `ToTensor`å°†ä¸€ä¸ªPILå›¾ç‰‡æˆ–è€…NumPyæ•°ç»„è½¬æ¢ä¸ºæµ®ç‚¹tensor, å¹¶ä¸”å°†å›¾ç‰‡çš„åƒç´ å€¼å½’ä¸€åˆ°[0, 1].

??? note "Lambdaå‡½æ•°çš„ä½œç”¨"

    åœ¨è¿™é‡Œ, æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå°†intè½¬æ¢ä¸ºone-hotç¼–ç tensorçš„å‡½æ•°. é¦–å…ˆ, å®ƒä¼šåˆ›é€ ä¸€ä¸ªå¤§å°ä¸º10çš„é›¶tensor. ç„¶åè°ƒç”¨äº†`scatter_`å‡½æ•°, ä½œç”¨æ˜¯å°†ç»™å®šå€¼$y$ç´¢å¼•ä¸Šçš„å€¼è®¾ç½®ä¸º1.

## åˆ›å»ºç¥ç»ç½‘ç»œ

ç¥ç»ç½‘ç»œåŒ…æ‹¬å¯¹æ•°æ®è¿›è¡Œæ“ä½œçš„å±‚/æ¨¡å—, `torch.nn`è¿™ä¸ªå‘½åç©ºé—´åŒ…å«äº†æ‰€æœ‰éœ€è¦æ„å»ºç¥ç»ç½‘ç»œçš„è„šæ‰‹æ¶. PyTorchä¸­æ‰€æœ‰çš„æ¨¡å—éƒ½æ˜¯`nn.Module`çš„å­ç±». ç¥ç»ç½‘ç»œæœ¬èº«å°±æ˜¯ä¸€ä¸ªåŒ…å«å…¶ä»–æ¨¡å—çš„æ¨¡å—, è¿™ç§åµŒå¥—ç»“æ„ä½¿å¾—æ„å»ºå¤æ‚çš„æ¶æ„éå¸¸ç®€å•.

### è·å–ç”¨äºè®­ç»ƒçš„è®¾å¤‡

æˆ‘ä»¬å¸Œæœ›åœ¨GPUæˆ–è€…MPSä¸Šè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹, å¯ç”¨ä¸‹åˆ—ä»£ç æ£€æŸ¥åŠ é€Ÿå™¨æ˜¯å¦åœ¨çº¿, å¦‚æœå¦, åˆ™ä½¿ç”¨CPU.

```py title='è¾“å…¥'
device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")
```

``` title='è¾“å‡º'
Using cuda device
```

### å®šä¹‰ç±»

æˆ‘ä»¬é€šè¿‡ç»§æ‰¿`nn.Module`çš„æ–¹å¼å®šä¹‰è‡ªå·±çš„ç¥ç»ç½‘ç»œ. ä½¿ç”¨`__init__`å‡½æ•°åˆå§‹åŒ–ç¥ç»ç½‘ç»œå±‚. æ¯ä¸ªå­ç±»éƒ½åœ¨`forward`å‡½æ•°ä¸­å¯¹äºè¾“å…¥æ•°æ®å®šä¹‰æ“ä½œ.

```py
class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits
```

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª`NeuralNetwork`, ç„¶åå°†å…¶ç§»åŠ¨åˆ°è®¾å¤‡.

```py title='è¾“å…¥'
model = NeuralNetwork().to(device)
print(model)
```

``` title='è¾“å‡º'
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
```

ä¸ºäº†ä½¿ç”¨è¿™ä¸ªæ¨¡å‹, æˆ‘ä»¬ç›´æ¥å‘å®ƒä¼ é€’æ•°æ®, è¿™å°†è‡ªåŠ¨è§¦å‘æ‰§è¡Œç±»å†…éƒ¨çš„`__call__`å‡½æ•°, è¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨è°ƒç”¨`forward`å‡½æ•°, ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨`forward`å‡½æ•°.

è°ƒç”¨æ¨¡å‹è¿”å›çš„ç»“æœæ˜¯ä¸€ä¸ªäºŒç»´çš„tensor, ç¬¬ä¸€ç»´å¯¹åº”çš„æ˜¯æ¯ä¸ªæ ·æœ¬çš„è¾“å‡ºç»“æœ, ç¬¬äºŒç»´å¯¹åº”çš„æ˜¯æ¯ä¸ªç±»åˆ«çš„åŸå§‹é¢„æµ‹å€¼(raw). æˆ‘ä»¬å°†é¢„æµ‹ç»“æœä¼ ç»™softmaxä¹‹åå¯ä»¥å°†ç¬¬äºŒç»´çš„è¾“å‡ºè½¬æ¢ä¸ºå¯¹åº”äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡.

```py title='è¾“å…¥'
X = torch.rand(1, 28, 28, device=device)
logits = model(X)
pred_probab = nn.Softmax(dim=1)(logits)
y_pred = pred_probab.argmax(1) # ç¬¬ä¸€ç»´åº¦æœ€å¤§çš„æ¦‚ç‡å¯¹åº”çš„index
print(f"Predicted class: {y_pred}")
```

``` title='è¾“å‡º'
Predicted class: tensor([7], device='cuda:0')
```

### æ¨¡å‹å±‚

æˆ‘ä»¬å°†ä¹‹å‰å®šä¹‰çš„FashionMNISTæ¨¡å‹åˆ†è§£ä¸€ä¸‹, å¹¶çœ‹çœ‹å¦‚æœæˆ‘ä»¬ä¼ å…¥äº†ä¸€ä¸ªéšæœºç”Ÿæˆçš„å°æ‰¹é‡3å¼ 28*28çš„å›¾ç‰‡çœ‹çœ‹å®ƒæ˜¯æ€ä¹ˆç»è¿‡ç½‘ç»œçš„.

```py title='è¾“å…¥'
input_image = torch.rand(3,28,28)
print(input_image.size())
```

``` title='è¾“å‡º'
torch.Size([3, 28, 28])
```

1. `nn.Flatten`

    æˆ‘ä»¬åˆå§‹åŒ–äº†ä¸€ä¸ª`nn.Flatten`å±‚å°†æ¯ä¸ª28*28çš„å›¾ç‰‡è½¬æ¢æˆä¸€ä¸ªè¿ç»­çš„æ•°ç»„è¡¨ç¤º784ä¸ªåƒç´ . æ‰¹æ¬¡çš„æ•°é‡3è¢«ä¿ç•™.

    ```py title='è¾“å…¥'
    flatten = nn.Flatten()
    flat_image = flatten(input_image)
    print(flat_image.size())
    ```

    ``` title='è¾“å‡º'
    torch.Size([3, 784])
    ```

2.  `nn.Linear`

    çº¿æ€§å±‚å¯¹è¾“å…¥ä½¿ç”¨å½“æ—¶çš„æƒé‡å’Œæˆªè·åšä¸€ä¸ªçº¿æ€§å˜æ¢.

    ```py title='è¾“å…¥'
    layer1 = nn.Linear(in_features=28*28, out_features=20)
    hidden1 = layer1(flat_image)
    print(hidden1.size())
    ```

    ``` title='è¾“å‡º'
    torch.Size([3, 20])
    ```

3.  `nn.ReLU`

    éçº¿æ€§æ¿€æ´»å‡½æ•°ç”¨äºåˆ›é€ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å¤æ‚æ˜ å°„, å®ƒè¢«æ”¾åœ¨çº¿æ€§å±‚ä¹‹å.

    ```py title='è¾“å…¥'
    print(f"Before ReLU: {hidden1}\n\n")
    hidden1 = nn.ReLU()(hidden1)
    print(f"After ReLU: {hidden1}")
    ```

    ``` title='è¾“å‡º'
    Before ReLU: tensor([[ 0.4158, -0.0130, -0.1144,  0.3960,  0.1476, -0.0690, -0.0269,  0.2690,
              0.1353,  0.1975,  0.4484,  0.0753,  0.4455,  0.5321, -0.1692,  0.4504,
              0.2476, -0.1787, -0.2754,  0.2462],
            [ 0.2326,  0.0623, -0.2984,  0.2878,  0.2767, -0.5434, -0.5051,  0.4339,
              0.0302,  0.1634,  0.5649, -0.0055,  0.2025,  0.4473, -0.2333,  0.6611,
              0.1883, -0.1250,  0.0820,  0.2778],
            [ 0.3325,  0.2654,  0.1091,  0.0651,  0.3425, -0.3880, -0.0152,  0.2298,
              0.3872,  0.0342,  0.8503,  0.0937,  0.1796,  0.5007, -0.1897,  0.4030,
              0.1189, -0.3237,  0.2048,  0.4343]], grad_fn=<AddmmBackward0>)


    After ReLU: tensor([[0.4158, 0.0000, 0.0000, 0.3960, 0.1476, 0.0000, 0.0000, 0.2690, 0.1353,
             0.1975, 0.4484, 0.0753, 0.4455, 0.5321, 0.0000, 0.4504, 0.2476, 0.0000,
             0.0000, 0.2462],
            [0.2326, 0.0623, 0.0000, 0.2878, 0.2767, 0.0000, 0.0000, 0.4339, 0.0302,
             0.1634, 0.5649, 0.0000, 0.2025, 0.4473, 0.0000, 0.6611, 0.1883, 0.0000,
             0.0820, 0.2778],
            [0.3325, 0.2654, 0.1091, 0.0651, 0.3425, 0.0000, 0.0000, 0.2298, 0.3872,
             0.0342, 0.8503, 0.0937, 0.1796, 0.5007, 0.0000, 0.4030, 0.1189, 0.0000,
             0.2048, 0.4343]], grad_fn=<ReluBackward0>)
    ```

4. `nn.Sequential`

    `nn.Sequential`æ˜¯ä¸€ä¸ªæœ‰é¡ºåºçš„æ¨¡å—å®¹å™¨, æ•°æ®ä¼šä¾ç…§å®ƒå®šä¹‰çš„é¡ºåºç»è¿‡å®šä¹‰åœ¨å®¹å™¨å†…çš„æ¨¡å—.

    ```py
    seq_modules = nn.Sequential(
        flatten,
        layer1,
        nn.ReLU(),
        nn.Linear(20, 10)
    )
    input_image = torch.rand(3,28,28)
    logits = seq_modules(input_image)
    ```

5. `nn.Softmax`

    ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚è¿”å›çš„æ˜¯åŸå§‹æ•°æ®, åº”è¯¥è¢«ä¼ å…¥softmaxå±‚å½’ä¸€åŒ–åˆ°[0, 1].

    ```py
    softmax = nn.Softmax(dim=1)
    pred_probab = softmax(logits)
    ```

### æ¨¡å‹å‚æ•°

ç¥ç»ç½‘ç»œä¸­çš„è®¸å¤šå±‚éƒ½æ˜¯æœ‰å¯è®­ç»ƒå‚æ•°çš„. å¯ä»¥é€šè¿‡æ¨¡å‹çš„`parameters()`æˆ–è€…`named_parameters()`æ–¹æ³•è®¿é—®æ‰€æœ‰çš„å‚æ•°.

```py title='è¾“å…¥'
print(f"Model structure: {model}\n\n")

for name, param in model.named_parameters():
    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")
```

``` title='è¾“å‡º'
Model structure: NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)


Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],
        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115]],
       device='cuda:0', grad_fn=<SliceBackward0>)

Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0155, -0.0327], device='cuda:0', grad_fn=<SliceBackward0>)

Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0116,  0.0293, -0.0280,  ...,  0.0334, -0.0078,  0.0298],
        [ 0.0095,  0.0038,  0.0009,  ..., -0.0365, -0.0011, -0.0221]],
       device='cuda:0', grad_fn=<SliceBackward0>)

Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0148, -0.0256], device='cuda:0', grad_fn=<SliceBackward0>)

Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0147, -0.0229,  0.0180,  ..., -0.0013,  0.0177,  0.0070],
        [-0.0202, -0.0417, -0.0279,  ..., -0.0441,  0.0185, -0.0268]],
       device='cuda:0', grad_fn=<SliceBackward0>)

Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0070, -0.0411], device='cuda:0', grad_fn=<SliceBackward0>)
```

## è‡ªåŠ¨å¾®åˆ†

åœ¨è®­ç»ƒç¥ç»ç½‘ç»œçš„æ—¶å€™, æœ€å¸¸ä½¿ç”¨çš„ç®—æ³•å°±æ˜¯åå‘ä¼ æ’­. åœ¨è¿™ä¸ªç®—æ³•ä¸­, å‚æ•°ä¼šæ ¹æ®å…¶å¯¹äºæŸå¤±å‡½æ•°çš„æ¢¯åº¦è¿›è¡Œè°ƒæ•´. ä¸ºäº†è®¡ç®—è¿™äº›æ¢¯åº¦, PyTorchæœ‰ä¸€ä¸ªå†…ç½®çš„å¾®åˆ†å¼•æ“å«åš`torch.autograd`. å®ƒæ”¯æŒä»»ä½•æœ‰å‘æ— ç¯å›¾(DAG)çš„è‡ªåŠ¨æ¢¯åº¦è®¡ç®—.

è€ƒè™‘ä¸€ä¸ªæœ€ç®€å•çš„ä¸€ä¸ªä¸€å±‚ç¥ç»ç½‘ç»œ, è¾“å…¥æ˜¯`x`, å‚æ•°æ˜¯`w`å’Œ`b`, è¿˜æœ‰ä¸€ä¸ªæŸå¤±å‡½æ•°.

```py
import torch

x = torch.ones(5)
y = torch.zeros(3)
w = torch.randn(5, 3, requires_grad=True)
b = torch.randn(3, requires_grad=True)
z = torch.matmul(x, w)+b
loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)
```

è¿™ä¸ªä»£ç å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸‹é¢çš„è¿™å¹…DAG:

<figure markdown='1'>
  ![](https://img.ricolxwz.io/8c22747ba6a3af69d4ed57dbf44cc8af.png){ loading=lazy width='500' }
</figure>

åœ¨è¿™ä¸ªå·¥ä½œä¸­, `w`å’Œ`b`æ˜¯å‚æ•°, æ˜¯æˆ‘ä»¬ä¼˜åŒ–çš„å¯¹è±¡. å› æ­¤, æˆ‘ä»¬å¿…é¡»è¦è®¡ç®—æŸå¤±å‡½æ•°å¯¹äºè¿™äº›å˜é‡çš„æ¢¯åº¦. ä¸ºäº†å®ç°è¿™ä¸€ç‚¹, æˆ‘ä»¬éœ€è¦è®¾ç½®è¿™äº›å˜é‡çš„`requires_grad`ä¸º`True`. ä½ å¯ä»¥åœ¨åˆå§‹åŒ–tensorçš„æ—¶å€™å°±è®¾ç½®`requires_grad=True`ä¹Ÿå¯ä»¥éšåé€šè¿‡`x.requires_grad_(True)`æ–¹æ³•è®¾ç½®.

ğŸŒŸå½“ä¸€ä¸ªtensorçš„`requires_grad`è¢«è®¾ç½®ä¸º`True`çš„æ—¶å€™

[^1]: Learn the basicsâ€”PyTorch tutorials 2.5.0+cu124 documentation. (ä¸è¯¦). å–è¯»äº 2024å¹´12æœˆ13æ—¥, ä» https://pytorch.org/tutorials/beginner/basics/intro.html
