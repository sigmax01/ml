---
title: 生成对抗网络
comments: false
---

## 核心思想[^1]

GAN的基本思想是, 首先我们有一个"生成器", Generator, 其实就是一个神经网络, 或者是更简单的理解, 他就是一个函数. 输入一组向量, 经由生成器, 产生一组目标矩阵(如果要生成图片, 那么矩阵就是图片的像素集合). 它的目的就是使得自己造样本的能力尽可能强, 强到什么程度呢, 强到判别网络无法判断我是真样本还是假样本. 同时我们还有一个"判别器", 判别器的目的是判别出来一张图片它是来自真实样本集还是假样本集. 假如输入的是真样本, 网络输出就接近1, 输入的是假样本, 网络输出接近0, 那么很完美, 达到了很好判别的目的. 

那为什么需要这两个组件呢? GAN在结构上受到了博弈论中的二人[零和博弈](https://zh.wikipedia.org/zh-hans/零和博弈)(即二人的利益之和为0, 一方的所得是另一方的所失)的启发, 系统由一个生成模型(G)和一个判别模型(D)构成. G捕捉真实数据样本的潜在分布, 并生成新的数据样本; D是一个二分类器, 判别输入是真实数据还是生成的样本. 生成器和判别器均可以采用深度神经网络. GAN的优化过程是一个极小极大博弈问题, 优化目标是达到[纳什平衡](https://wiki.mbalib.com/wiki/纳什均衡). 

<figure markdown='1'>
![](https://img.ricolxwz.io/61877d501c1d15633367f9c1f285f05e.jpg){ loading=lazy width='400' }
</figure>

首先, 我们有两个关键组件, 生成器(G)和判别器(D), 一开始G-V1生成了一些手写体的图片, 然后丢给D-V1, 同时我们也需要把真实图片也送给D-V1, 然后D-V1根据自己的"经验"(其实就是当前的网络参数)结合真实图片数据, 来判断G-V1生成的图片是否符合要求. 

很明显, 第一代的G是无法骗过D的, 那怎么办? 那G-V1就"进化"为G-V2, 以此生成更加高质量的图片来骗过D-V1. 然后为了识别进化后生成更高质量图的图片的G-V2, D-V1也升级为了D-V2... 就这样一直迭代下去, 直到生成网络G-Vn生成的假样本进去了判别网络D-Vn以后, 判别网络给出的结果是一个接近0.5的值, 也就是说明判别不出来了, 这个就是那是平衡了. 这时候回去看生成的图片, 发现它们真的很逼真了.

那么具体它们是怎么互相学习的呢? 首先是D的学习:

<figure markdown='1'>
![](https://img.ricolxwz.io/e02d83044705d3e78746de1b710cb41a.png){ loading=lazy width='400' }
</figure>

首先, 我们随机初始化生成器G, 并输入一组随机向量, 以此产生一些图片, 并把这些图片标注为0(假图片). 同时把来自真实分布中的图片标注为1(真图片). 两者同时丢到判别器D中, 以此来训练判别器. 实现当输入是真图片的时候, 判别器给出的是接近于1的分数, 而输入假图片的时候, 判别器给出接近于0的低分.

接着是G的学习:

<figure markdown='1'>
![](https://img.ricolxwz.io/78f21c5d2514f407424fb89e11be3e5d.png){ loading=lazy width='400' }
</figure>

对于生成网络, 目的是生成尽可能逼真的样本. 所以在训练生成网络的时候, 我们需要联合判别网络才能达到训练的目的. 也就是说, 通过将两者串接起来的方式来产生误差从而得以训练生成网络. 步骤是: 我们通过随机向量(噪声数据)经由生成网络产生一组假数据, 并将这些假数据都标记为1. 然后将这些假数据输入到判别网络里面, 判别器肯定会发现这些标榜为真实数据(标记为1)的输入都是假数据(给出低分), 这样就产生了误差, 在训练这个串接的网络的时候, 一个很重要的草做是不要让判别网络的参数发生变化, 只是把误差一直传, 传到生成网络那块后更新网络的参数. 这样就完成了对生成网络的训练了. 

在完成了生成网络的训练之后, 我们又可以产生新的假数据去训练判别网络了. 我们把这个过程称作为单独交替训练. 同时要定义一个迭代次数, 交替迭代到一定次数之后停止即可.

## 数学推导

### 最大似然估计

最大似然估计, 就是利用已知的样本结果信息, 反推最具有可能性(最大概率)导致这些样本结果出现的模型参数值. 样本从某一个客观存在的模型中抽样得来, 然后根据样本来计算该模型的数学参数, 即模型已定, 参数未知.

假设一组含有$m$个样本的数据集$X = \{x^{(1)}, x^{(2)}, x^{(3)}, \ldots, x^{(m)}\}$, 该数据集中的样本是从某个现实的数据生成分布$p_{data}(x)$中独立采样生成的. 这个现实的数据生成分布的具体形式和参数是未知的, 换句话说, 我们完全无法了解这个分布, 只能通过已有的数据来近似理解和建模它.

令$p_{model}(x;\theta)$是一个由参数$\theta$(未知)确定在相同空间上的概率分布, 也就是说, 我们的目的就是找到一个合适的$\theta$使得$p_{model}(x;\theta)$尽可能地去接近$p_{data}(x)$.

我们利用真实分布$p_{data}(x)$中生成出来的数据集$X$去估算总体概率为$L(\theta) = \prod_{i=1}^{m} p_{model}(x^{(i)}; \theta)$. 

然后我们计算出使得$L$最大的这个参数$\theta_{ML}$, 也就是说, 对$\theta$的最大似然估计被定义为:

$\theta_{ML} = \arg \max_{\theta} p_{model}(X; \theta) = \arg \max_{\theta} \prod_{i=1}^{m} p_{model}(x^{(i)}; \theta)$

$p_{model}(X; \theta) \rightarrow f(x^{(1)}, x^{(2)}, x^{(3)}, ..., x^{(m)} | \theta)$

$\prod_{i=1}^{m} p_{model}(x^{(i)}; \theta) \rightarrow f(x^{(1)}|\theta) \cdot f(x^{(2)}|\theta) \cdot f(x^{(3)}|\theta) ... f(x^{(m)}|\theta)$

为什么要让$L$最大? 可以这样想: 我们从真实的分布中取得了这些数据$X=\{x^{(1)}, x^{(2)}, x^{(3)}, \ldots, x^{(m)}\}$, 那为什么会偏偏在真实分布中取得这些数据呢? 是因为取得这些数据的概率更大一些, 而此时我们做的就是人工设计的一个由参数$\theta$控制的分布$p_{model}(x;\theta)$来去拟合真实分布$p_{data}(x)$, 换句话说, 我们通过一组数据$X$去估算第一个参数$\theta$使得这组数据$X$在人工设计的分布中$p_{model}(x;\theta)$被抽样出来的可能性最大, 所以让$L$最大就感觉合乎情理了.

多个概率的乘积会因为很多原因不便于计算. 例如, 计算中很可能会出现指数下溢(概率值通常介于0和1之间, 多个概率相乘的结果会越来与小, 计算机用有限的位数来表示浮点数, 所能表示的最小正数有一个下限, 当计算结果小于这个下限的时候, 就会发生下溢, 近似为0). 为了得到一个便于计算的等价优化问题, 我们观察到似然对数不会改变其$\arg \max$, 于是将成绩转换为了便于计算的求和形式: 

$\theta_{ML} = \arg \max_{\theta} \sum_{i=1}^{m} \log p_{model}(x^{(i)}; \theta)$

:fontawesome-solid-circle-question: 但是上述直接使用样本的对数似然总和作为优化目标可能会因为样本的不同而有较大的波动, 尤其是在样本量$m$较小的情况下, 优化可能会受到噪声的影响较大. 为此, 由于重新缩放代价函数的时候$\argmax$不会改变, 可以引入期望对似然函数进行平均化. 随着样本量的增大, 样本的均值会趋近于总体均值, 即经验分布$\hat{p}_{data}(x)$会越来越接近真实分布$p_{data}(x)$. 通过引入期望作为目标, 能够获得以下优点: 平滑优化(期望操作有助于减少由样本的随机性或噪声引起的波动), 减少过拟合(避免了模型过于拟合有限样本的波动, 提升了估计的泛化能力). 

### KL散度

一种解释最大似然估计的观点是将其看作是最小化训练集上的经验分布$\hat{p}_{data}$和模型分布$p_{model}(x;\theta)$之间的差异, 两者之间的差异程度可以用KL散度来度量, KL散度的含义是分布保留了多少原始分布的信息.  

关于KL散度, 在信息论中[提到](https://gk.ricolxwz.de/information-theory/what-is-information/#KL散度)过.

KL散度在这里被定义为$D_{KL}(\hat{p}_{data}||p_{model})=E_{x\sim \hat{p}_{data}}[\log \hat{p}_{data}(x)-\log p_{model}(x)]$. 注意到, 这里的公式其实是和在信息论中所写的公式有一点出入, 这是因为期望和加权求和的等价性. 

对于离散分布来说, 期望可以表示为随机变量取值的加权平均, 其中权重是对应取值的概率. 即$E_{X \sim p}[f(X)] = \sum_{x} p(x) f(x)$. 在KL散度的计算中, 可以应用上述的思想: $D_{\text{KL}}(P || Q) = E_{x \sim P} \left[ \log \frac{P(x)}{Q(x)} \right] = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}$.

???+ tip "Tip"

    对于连续的分布来说, 也有相似的公式: 

    $\mathbb{E}{X \sim p}[f(X)] = \int_x p(x) f(x) \, dx$


左边这一项$E_{x\sim \hat{p}_{data}}[\log \hat{p}_{data}(x)]$仅涉及到数据的原始分布, 和模型是无关的. 这意味着当训练模型最小化KL散度的时候, 我们只需要最小化右边的这个部分, 即$-E_{x\sim \hat{p}_{data}}[\log p_{model}(x)]$. 

结合上面对最大似然的解释, 开始推导$\theta_{ML}$:

(注意到, 第4行是把期望展开为前一项然后再减去一个和$\theta_{ML}$无关的项(不会影响到$\theta_{ML}$的取值, 所以可以随便加), 而后面变形为KL散度做准备)

$$\begin{align*}
\theta_{ML} &= \argmax_{\theta} \prod_{i=1}^m p_{\text{model}}(x^{(i)}; \theta) \\
            &= \argmax_{\theta} \log \prod_{i=1}^m p_{\text{model}}(x^{(i)}; \theta) 
            = \argmax_{\theta} \sum_{i=1}^m \log p_{\text{model}}(x^{(i)}; \theta) \\
            &\approx \argmax_{\theta} \mathbb{E}_{x \sim \hat{p}_{\text{data}}} [\log p_{\text{model}}(x; \theta)] \\
            &= \argmax_{\theta} \int_x \hat{p}_{\text{data}}(x) \log p_{\text{model}}(x; \theta) \, dx 
            - \int_x \hat{p}_{\text{data}}(x) \log \hat{p}_{\text{data}}(x) \, dx \\
            &= \argmax_{\theta} \int_x \hat{p}_{\text{data}}(x) [\log p_{\text{model}}(x; \theta) - \log \hat{p}_{\text{data}}(x)] \, dx \\
            &= \argmax_{\theta} -\int_x \hat{p}_{\text{data}}(x) 
            \log \frac{\hat{p}_{\text{data}}(x)}{p_{\text{model}}(x; \theta)} \, dx \\
            &= \arg\min_{\theta} KL(\hat{p}_{\text{data}}(x) \| p_{\text{model}}(x; \theta))
\end{align*}$$

最小化KL散度其实就是最小化分布之间的交叉熵, 任何一个由负对数似然函数组成的损失都是定义在训练集$X$上的经验分布$\hat{p}_{data}$和定义在模型上的概率分布$p_{model}$之间的交叉熵. 例如, 均方误差就是定义在经验分布和高斯模型之间的交叉熵.  最优$\theta$在最大化似然函数和最小化KL散度的时候是相同的. 

那么要怎么找到一个比较好的$p_{model}(x;\theta)$呢? 传统的生成模型(例如GMM或者其他统计模型)无法很好地处理复杂的高维数据分布, 而生成对抗网络(GAN)引入了神经网络来建模数据分布, 从而生成更加复杂和逼真的数据, 所以$p_{model}(x;\theta)$在GAN里面是一个神经网络产生的分布.

<figure markdown='1'>
![](https://img.ricolxwz.io/383d1f260a152205f621dd1750abb54c.png){ loading=lazy width='400' }
</figure>

假设$z$是从高斯分布$p_{prior}(z)$中采样而来, 然后通过一个神经网络(也就是G)得到$x$, 这个$x$满足另一个分布$p_{model}(x;\theta)$, 然后我们要找到这个分布的参数$\theta$使得它和真实分布越相近越好, 这里的$p_{model}(x;\theta)$可以写作: $p_G(x) = \int p_{prior}(z) I(G(z) = x) dz$, 这个公式的含义是, 生成的样本$x$是通过输入噪声$z$生成的, 而$z$是一个已知的先验分布$p_{prior}(z)$中采样得到的, 生成$x$的概率是所有可能的$z$贡献的概率总和, $I(G(z)=x)$是指示函数, 当$G(z)$的输出等于$x$的时候, $I(G(z)=x)$的值为$1$, 否则为$0$, 它的作用是筛选出哪些$z$能生成特定的$x$.

难点在于, 在现实中, 如GMM等模型, 由于$G(z)$的复杂性, 基本上很难找到$x$的分布$p_{model}(x;\theta)$, 而GAN的作用就是通过神经网络调整参数$\theta$, 让G产生的分布尽量接近真实分布.

### JS散度

JS散度(Jensen-Shannon Divergence)衡量了两个概率分布的相似度, 基于KL散度的变体, 解决了KL散度非对称的问题, 也就是说, 在KL散度下, $D_{KL}(\hat{p}_{data}||p_{model})\neq D_{KL}(p_{model}||\hat{p}_{data})$. JS散度是对称的, 其取值在$0$到$1$之间, 定义如下:

$$JSD(P \| Q) = \frac{1}{2} KL\left(P \| \frac{P + Q}{2}\right) + \frac{1}{2} KL\left(Q \| \frac{P + Q}{2}\right)$$

KL散度和JS散度在度量的时候还有一个问题, 如果两个分布离得很远, 完全没有重叠的时候, 那么散度的值是没有意义的. 这在学习算法中是比较致命的, 这就意味着在这一点的梯度为$0$了, 梯度消失了.

## 算法推导

首先, 来重申一下重要的参数和名词.

- 生成器, G
    - G是一个函数, 输入是$z$, 输出是$x$
    - 给定一个先验分布$p_{prior}(z)$和一个反映生成器G的分布$p_{G}(x)$, $p_G(x)$对应的就是$p_{model}(x;\theta)$
- 判别器, D
    - D也是一个函数, 输入是$x$, 输出是一个标量
    - 主要是评估$p_G(x)$和$p_{data}(x)$之间到底有多少不同, 也就是他们之间的交叉熵

现给出一条目标公式:

$$V = \mathbb{E}_{x \sim p_{\text{data}}} \left[ \log D(x) \right] + \mathbb{E}_{x \sim p_G} \left[ \log (1 - D(x)) \right]$$

这里的$D(x)$表示的是判别器的输出, 如果$D(x)=1$, 则判别器会认为$x$是完全真实的, 如果$D(x)=0$, 判别器会认为$x$是完全假的. 这个公式的直觉是, 对于真实样本, 希望$D(x)$尽可能接近$1$, 越接近$1$, 损失趋近于$0$(从负方向趋近); 对于生成样本, 希望$D(x)$尽可能接近$0$, 损失趋近于$0$(从负方向趋近), 所以需要最大化$V$.

这条公式衡量的是$p_G(x)$和$p_{data}(x)$之间的不同程度. 对于GAN, 做法是, 给定G, 找到一个D^*^使得$V(G, D)$最大, 即$\max_D V(G, D)$, 直觉上理解为: 生成器固定的时候, 就是通过判别器尽可能地将生成图片和真实图片区别开来, 也就是需要最大化两者之间的交叉熵: $D^*=\argmax_D V(G, D)$

然后, 要是固定D, 使得$\max_D V(G, D)$最小的这个G代表的就是最好的生成器. 所以G的终极目标就是找到G^*^, 找到了G^*^我们就找到了分布$p_G(x)$对应的参数$\theta_G$: $G^*=\arg \min_G\max_D V(G, D)$

上面的步骤给出了我们期望优化的目标, 现在按照步骤对目标进行推导.

### 寻找最好的D^*^

首先是第一步, 给定G, 找到一个最好的D^*^使得$V(G, D)$最大, 即求$\max_D V(G, D)$. 

$$\begin{align*}
V &= \mathbb{E}_{x \sim p_{\text{data}}} \left[ \log D(x) \right] + \mathbb{E}_{x \sim p_G} \left[ \log (1 - D(x)) \right] \\
  &= \int_x p_{\text{data}}(x) \log D(x) \, dx + \int_x p_G(x) \log (1 - D(x)) \, dx \\
  &= \int_x \left[ p_{\text{data}}(x) \log D(x) + p_G(x) \log (1 - D(x)) \right] \, dx
\end{align*}$$

[^1]: 生成对抗网络——原理解释和数学推导—黄钢的部落格|Canary Blog. (不详). 取读于 2024年12月5日, 从 https://alberthg.github.io/2018/05/05/introduction-gan/