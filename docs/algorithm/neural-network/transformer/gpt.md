---
title: GPT
comments: true
---

# GPT[^1]

## 摘要

NLP包括很多任务, 如[文本蕴含](https://en.wikipedia.org/wiki/Textual_entailment, "判断一个文本片段是否能够逻辑上推导出另一个文本片段, <br>可用于信息检索, 问答系统, 自动摘要等任务"), [问答系统](https://en.wikipedia.org/wiki/Question_answering "针对用户提出的问题, 系统能够理解问题并给出准确的答案, <br>可用于搜索引擎, 智能客服, 知识库问答等任务"), [语义相似度评估](https://en.wikipedia.org/wiki/Semantic_similarity "评估两个文本在语义上的相似度, <br> 可用于信息检索, 文本聚类, 抄袭检测等任务"), [文档分类](https://en.wikipedia.org/wiki/Document_classification "将文档归类到预定义的类别中 <br>可用于垃圾邮件过滤, 新闻分类, 情感分析等任务"). 虽然大型未标注的语料库非常充足, 但是用于特定任务的已标注的文本确非常少, 导致[判别式模型](/dicts/discriminative-and-generative-model)很难在这些NLP任务中取得很好的性能. 作者展示了一种生成式预训练模型, Generative Pre-trained Model, 它通过在大量未标注的语料上训练, 学习通用的语言表示, 然后, 针对特定任务通过少量标注数据进行微调, 可以很好的完成任务. 这种预训练模型在性能上甚至优于那些专门为特定任务而设计的判别式模型, 在12项任务中的9项都打到了SOTA的表现. 在Stories Cloze Test上获得了8.9%的绝对提升, 在RACE上为5.7%, 在MultiNLI上为1.5%.

## 背景 {#intro}

### 动机

从raw文本中直接学习的能力对减轻NLP对监督学习依赖至关重要. 许多深度学习的方法需要大量的手工标注的数据, 导致它们在很多领域应用的潜力受到限制. 在这种情况下, 对于未标记文本中的语言信息进行建模, 相比于收集更多的高质量的标注, 不失为一种可行的方案. 而且, 即使在有足够多的带标注的数据的情况下, 以无监督方式学习良好的表示也能够显著地提高性能. 迄今为止, 最令人信服的证据是, [词嵌入预训练](/algorithm/neural-network/word-embedding/#transfer-learning)的广泛应用.

???+ note "优化目标和NLP任务的区别"

    优化目标(Optimization Objective)是训练模型的一种**手段和策略**, 侧重于如何从数据中提取有效的信息. NLP任务是现实中需要解决的具体问题, 是**最终需求**, 评估模型在这些问题上的表现. 优化目标的典型例子有语言建模(Language Modeling), 预测下一个单词或者填补句中的空白, 如BERT中的MLM; 对比学习(Contrastive Learning), 最小化正样本之间的相似性, 最小化负样本之间的相似性等等... NLP任务的典型例子是文本分类, 机器翻译, 问答系统, 文本生成等等...

    | **维度**   | **优化目标**                     | **NLP任务**                     |
    |------------|----------------------------------|----------------------------------|
    | **定义**   | 指导模型训练的数学目标           | 解决实际语言处理问题的具体功能   |
    | **阶段**   | 用于模型训练                    | 用于模型评估或实际应用           |
    | **范围**   | 通常通用, 适用于多个任务         | 具体、与应用场景相关             |
    | **目标对象**| 优化模型参数, 学习表示          | 评估模型是否能够完成特定任务     |
    | **举例**   | 语言建模、对比学习目标           | 文本分类、机器翻译、问答系统     |

从未标注数据中提取超越词级别的信息(即词嵌入获得的信息)是具有挑战性的, 主要有两个原因:

1. **不清楚哪种优化目标最能有效地学习适用于迁移的文本表示, 因为不同的下游任务(如情感分析, 文本蕴含, 机器翻译等)对文本表示的需求不同.** 近期的研究探索了多种优化目标, 比如语言建模(预测下一个词或者MLM), 机器翻译, 篇章连贯性等等, 每种方法都在不同的任务上优于其他方法, 如语言建模可能对生成任务表现良好, 篇章连贯性可能对需要理解文本逻辑关系的任务(如文本蕴含)更有优势, 机器翻译可能在多语言任务中更加有效.
2. **到目前为止还没有在最有效的迁移这些学习到的表示到目标任务的方法上达成一致.** 现有方法通常包括:
    1. 针对特定任务调整模型架构. 如为分类任务添加分类头, 为序列标注任务添加序列解码模块, 这些调整需要针对不同任务进行设计, 缺乏通用性.
    2. 使用复杂的训练策略. 如微调, 调整预训练模型参数, 使其适应目标任务; 冻结部分参数, 仅调整模型的一部分, 减少计算开销; 逐层解锁, 从浅层到深层逐步调整参数, 这些学习策略的设计和选择通常需要大量实验和经验, 增加了开发的复杂性.
    3. 添加辅助学习目标: 除了主任务的目标函数外, 引入额外的优化目标来辅助模型训练, 如在情感分析任务中, 同时训练模型识别文本中的关键情感用语; 使用对比学习目标增强嵌入的语义一致性.

这些不确定性使得开发有效的[半监督学习](https://zh.wikipedia.org/zh-hans/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0)方法变得困难.

### 方案

在这篇文章中, 作者探索了一种用于语言理解任务的半监督学习方法, 该方法包括**无监督预训练和监督微调**. 目标是学习到一种通用的表征, 该表征能够在少量调整的情况下迁移到各种任务. 他们假设可以访问大量的未标记文本语料库和几个手动标注的训练示例(目标任务)的数据集, 并不要求这些目标任务和未标注语料库所代表的领域相同. 他们的训练分为两个阶段: 第一个阶段, 在未标记的数据上使用语言建模作为优化目标来学习神经网络模型的初始参数. 第二个阶段, 使用相应的监督目标将这些参数适应于各种目标任务.

对于模型架构, 他们选择了Transformer, 他已经被证明可以用于多种任务, 如机器翻译, 文件生成和句法分析. 这个模型相比于RNN能够提供用于处理文本中长期依赖关系的更结构化的记忆, 从而能够在各种目标任务中实现强大的迁移性能. 在迁移的国臣各种, 他们使用了遍历式方法(Traversal-style Approaches)将结构化文本输入(如表格, 树状数据)转化为单一的, 连续的token序列, 使其可以直接输入到预训练的模型中, 避免了额外的结构化处理模块, 这种方式可以以很少的对预训练模型的调整实现对目标任务的高效适配.

### 评估

除了上述的的评估方法以及结果, 它们还衡量了zero-shot的表现. 并发现, 预训练模型获得了可以用于下游任务的有用语言知识.

???+ note "什么是zero-shot"

    zero-shot(零样本学习)是机器学习和NLP中的一种技术或者学习范式. 指的是模型在没有见过任何目标任务或者目标类别的训练样本情况下, 能够直接对新任务或者新类别进行预测.

## 相关工作

### NLP领域的半监督学习

他们的工作主要属于NLP的半监督学习范畴. 该范式在序列标注(如NER)或者文本分类等任务中得到了广泛引用. 较早的半监督学习方法利用未标注的数据来计算词汇级别或者短语级别的统计信息, 如词频或者共现信息, 然后, 使用这些统计信息喂给监督学习模型. 近年来, 研究人员提出了利用词嵌入的方法, 这些嵌入是在未标注的语料上训练的, 它将短语隐射到一个密集的向量空间, 将词汇的语义转化为向量表达. 然而, 这些方法主要关注传递词汇级别的信息, 而作者的工作是理解更加复杂/高层次的语义信息. 最近的工作调查了从未标注数据中学习利用超越词汇层次的语义信息, 基于句子级别, 段落级别的嵌入的模型, 可以使用未标记语料库进行训练, 从而将文本编码为适合各种目标任务的向量表示.

### 无监督预训练

**无监督预训练+有监督微调(two-stages)是半监督学习的一种特例, 其目的是去找到一个好的初始化点而不是修改监督学习的优化目标.** 早期的工作主要集中在图像分类和回归任务中, 探讨无监督预训练是否能提高模型在这些任务上的表现. 后续的研究对无监督预训练进行了更加详细的分析和验证, 发现, 无监督预训练不仅仅是为了找到一个好的初始点, 它还充当了一种正则化机制, 帮助模型避免过拟合. 在最近的工作中, 无监督预训练方法已经被广泛地应用于不同的深度学习任务中, 尤其是在图像分类, 语音识别, 机器翻译等任务中都得到了较好的效果.

???+ note "对于第一句话的个人理解"

    🐝无监督学习(预训练阶段)的优化目标和监督学习(微调阶段)的优化目标通常是不同的, 无监督学习阶段的优化目标是语言模型(预测下一个词或者MLM), 而监督学习阶段的优化目标通常和无监督学习阶段的优化目标不同, 这个时候的目标是直接优化与具体任务相关的目标函数(如分类的交叉熵损失, 回归的均方误差等). 无监督学习的优化目标和监督学习的优化目标**通常不同**.

与我们最相似的研究使用语言模型作为优化目标对神经网络进行预训练, 然后对目标任务进行监督学习微调. Dai等人[^2]和Howard, Ruder[^3]的工作都采用了上述的方法来改进文本分类任务. 但是, 他们使用的是LSTM模型(因为那个时候Transformer还没有出来). 与LSTM不同, 作者选择了Transformer, 它能捕获全局注意力而且能够使用GPU进行密集并行计算. 而且, 作者不仅仅在文本分类任务上取得了不错的结果, 还在其他的下游任务中展现出了良好的性能, 如自然语言推理, 同义句检测和故事补全, 具有很好的泛化能力.

还有一些其他的方法使用了从预训练的语言模型或者机器翻译模型中提取的隐藏层表示作为辅助特征, 并在目标任务上训练一个监督学习模型. 简单来说, 这些方法将预训练模型生成的特征用作输入, 进行监督学习. 但是, 这种方法需要在每个目标任务上引入大量新的参数, 导致模型的复杂性大大增加. 与之相比, 作者的方法在进行任务迁移的时候只需要对模型架构进行极小的修改, 不需要为每个任务训练大量新的参数, 减少计算和存储开销.

### 辅助训练目标 {#auxiliary-training-objectives}

辅助训练目标(Auxiliary Training Objectives)指在监督学习模型的主要优化目标之外, 加一些额外的无监督优化目标, 它是一种实现半监督学习的另一种形式(这种就没有two-stages, 相当于是结合了有监督学习和无监督学习的优化目标, 同时优化它俩的损失函数, 是one-stage). 如Rei等人[^5]在目标任务训练过程中, 添加了一个辅助的语言建模目标, 这意味着在微调阶段, 模型不仅优化目标任务的损失函数, 还同时优化语言建模的损失函数. Collobert和Weston[^4]在训练模型的时候, 不仅仅专注于主要任务(语义角色标注), 还同时优化了词性标注, 分块, NER, 语言建模的损失函数. 作者的研究也引入了辅助优化目标, 作者强调, 虽然它们也使用了辅助目标, 但是, two-stages的方案(即无监督预训练+有监督微调)已经足够强大, 使得这种形式的半监督学习的必要性相对较低.

## 框架

### 无监督预训练

给定一个未标注的语料$\mathcal{U}=\{u_1, ..., u_n\}$. 使用一个标准的语言建模优化目标去最大化以下似然.

$$L_1(\mathcal{U}) = \sum_i \log P(u_i \mid u_{i-k}, \dots, u_{i-1} ; \Theta)$$

???+ question "从该公式看GPT是生成式还是判别式模型"

    该公式$L_1(\mathcal{U}) = \sum_i \log P(u_i \mid u_{i-k}, \dots, u_{i-1} ; \Theta)$描述了GPT在训练过程中对序列中每个词语(或子词、标记)的条件概率进行建模, 即在给定前面若干个词的情况下, 计算下一个词出现的概率. 通过对整个序列中所有词的条件概率进行连乘(或对数连加), GPT实际上在隐式地建模整个序列的联合概率分布

    $$P(u_1, u_2, \dots, u_T) = \prod_{i} P(u_i \mid u_{i-k}, \dots, u_{i-1}; \Theta)$$

    与判别式模型相比, 判别式模型通常关心的是给定输入后某一特定标签或类别的条件概率(如$P(\text{label}\mid \text{input})$), 而不直接对输入本身的联合分布建模. 相反, 生成式模型则试图对数据的概率分布进行刻画, 能够基于此概率分布"生成"新的样本. GPT在训练时的优化目标与最终实现的功能本质上符合生成式模型的特点: 它通过对序列的统计规律进行学习, 从而能够在给定前文条件下, 自然地生成后续的词语序列.

    因此, 从上述公式及GPT的训练目标来看, GPT是生成式模型. 关于生成式和判别式模型, 请见[这里](/dicts/discriminative-and-generative-model).

其中, $k$是窗口的大小, 条件概率$P$由一个参数为$\theta$的神经网络进行建模, 这个神经网络使用SGD进行训练. 在本文的实验中, 作者使用的是一个多层的Transformer解码器, 这个模型利用了多头注意力机制, 然后接入一个position-wise的前馈神经网络(每一个transformer块内都会有这个FNN).

???+ note "什么是position-wise的FNN"

    在position-wise的情况下, 每个序列位置的词向量都是单独处理的, 本质上是, 每个位置的输入特征$x_i$会被单独送入一个共享的FNN, 这里的共享指的是不同输入之间使用的是一个权重$W_1, W_2$, 每个位置的计算是独立的, 假设输入词向量$x_i$的维度是$d$, 那么这个FNN的输入层神经元数量就有$d$个. 如果是非point-wise, 那么输入层神经元的数量就有$nd$个, $n$为输入词向量的数量.

    | 情况                 | 输入神经元数量           | 说明                                     |
    |----------------------|--------------------------|------------------------------------------|
    | position-wise    | $d$                   | 每个位置独立处理, FNN 对每个位置共享权重, 但不跨位置交互 |
    | 非position-wise | $n \cdot d$           | 整个序列作为整体处理, 允许跨位置的特征交互          |

无监督预训练的架构可以表示为:

$$\begin{align*}
h_0 &= UW_e + W_p \\
h_l &= \text{transformer\_block}(h_{l-1}), \, \forall l \in [1, n] \\
P(u) &= \text{softmax}(h_n W_e^T)
\end{align*}$$

其中, $U=\{u_{-k}, ..., u_{-1}\}$是token的上下文one-hot编码, $W_e$是词嵌入矩阵, $W_p$是位置编码. $h_{l-1}$的输出作为$l$层的transformer块的输入, $\forall l\in [1, n]$表示总共有$n$层transformer块. $h_n$表示的是最后一层transformer块的输出, $W_e^T$是词嵌入矩阵的转置, 作用是将模型的输出映射回词汇表空间. Softmax将输出转换为每个词的概率分布.

### 监督微调

使用语言建模作为优化目标进行无监督预训练后. 我们将这些参数用于初始化监督微调目标任务. 假设有一个标注数据集$\mathcal{C}$, 其中的每一个instance都由一组输入标记$x^1, ..., x^m$和一个标签$y$组成. 这些输入会输入预训练的模型, 获得最后一个transformer块的激活值$h_l^m$, 然后通过一个线性输出层(这个线性输出层在预训练的时候是没有的)预测标签$y$, 用公式表示为:

$$P(y|x^1, \dots, x^m) = \text{softmax}(h_l^m W_y)$$

以下的公式代表的是监督微调阶段的优化目标:

$$L_2(\mathcal{C}) = \sum_{(x, y)} \log P(y|x^1, \dots, x^m)$$

作者还提到, 除了优化目标$L_2(\mathcal{C})$, 还加入了语言建模作为[辅助训练目标](#auxiliary-training-objectives)$L_1(\mathcal{C})$, 这个辅助目标可以帮助模型提高泛化能力, 加速收敛. 所以, 在微调过程中, 最终的目标函数$L_3(\mathcal{C})$是监督目标$L_2(\mathcal{C})$和辅助训练目标$L_1(\mathcal{C})$的加权和, 主优化目标的权重为$\lambda$, 所以, 最终的目标函数为:

$$L_3(\mathcal{C}) = L_2(\mathcal{C}) + \lambda \cdot L_1(\mathcal{C})$$

总之而言, 在微调阶段, 我们只需要额外的参数$W_y$和分隔符标记的嵌入(在下一个小节描述).

### 任务相关输入转换

对于某一些任务, 如文本分类, 我们可以直接如上个小节所述的样子直接微调. 另外一些任务, 如QA或者TE, 它们的输入常常是局域结构的. 由于我们的预训练模型是在连续的文本序列上训练的, 所以需要一点点的调整来应用到这些任务中. 之前的研究提出了一种方法, 即在预训练的表示之上, 设计特定于任务的网络架构, 这种方法的问题在于, 它重新引入了针对具体任务的定制化操作, 也就是说, 虽然迁移学习的目的是为了减少不同任务的重复劳动, 但是这种方法通过设计特定架构增加了复杂性.

<figure markdown='1'>
![](https://img.ricolxwz.io/38a996b4fdbe0e3e44027a43a10f9011.webp#only-light){ loading=lazy width='500' }
![](https://img.ricolxwz.io/38a996b4fdbe0e3e44027a43a10f9011_inverted.webp#only-dark){ loading=lazy width='500' }
<figcaption>Transformer的结构(左); 对于不同的下游任务微调阶段输入的转换, 使用Traversal-style Approaches将结构化的输入转化为单一的, 连续的token序列(右)</figcaption>
</figure>

相反的, 作者使用一种遍历式的方法(Traversal-style Approache), 将结构化的输入转化成一个预训练模型可以处理的有顺序的序列, 从而减少针对不同任务的架构上的大幅修改. 这些修改如下文所示, 如上图所示. 所有的转换都包含一个随机初始化的开头和结尾token(<$s$>, <$e$>).

- 文本蕴含任务: 将判断前提(premise, $p$)和假设$h$的词序通过一个分隔符($)拼接起来, 作为模型的输入
- 相似度任务: 针对输入的句子对, 生成两种句子顺序, 即$A; B$和$B; A$, 用分隔符将$A; B$分割, 分别独立处理这两种顺序, 生成两个序列表示($h_l^{m}$), 将两个序列的表示按照元素相加后, 再送入线性输出层, 得到相似度分值
- 问答和常识推理: 任务是给定一个文档上下文$z$, 一个问题$q$和多个可能的答案$\{a_k\}$, 选出最可能的正确答案. 将上下文$z$, 问题$q$和每个可能的答案$a_k$拼接成总共$k$个序列$[z; q; $; a_k]$, 每个拼接的序列单独输入模型处理, 生成表示, 使用softmax正则化, 将模型的输出转化为各答案的概率分布

???+ note "为什么叫做遍历式的方法"

    之所以这样命名, 最明显的就是相似度任务和问答, 常识推理任务中的输入转换. 相似度任务需要"遍历"所有可能的句子排列方式, 问答任务需要遍历所有可能的答案和问题, 上下文的组合...

[^1]: Radford, A. (2018). Improving language understanding by generative pre-training. https://www.mikecaptain.com/resources/pdf/GPT-1.pdf
[^2]: Dai, A. M., & Le, Q. V. (2015). Semi-supervised sequence learning (No. arXiv:1511.01432). arXiv. https://doi.org/10.48550/arXiv.1511.01432
[^3]: Howard, J., & Ruder, S. (2018). Universal language model fine-tuning for text classification (No. arXiv:1801.06146). arXiv. https://doi.org/10.48550/arXiv.1801.06146
[^4]: Collobert, R., & Weston, J. (2008). A unified architecture for natural language processing: Deep neural networks with multitask learning. Proceedings of the 25th International Conference on Machine Learning, 160–167. https://doi.org/10.1145/1390156.1390177
[^5]: Rei, M. (2017). Semi-supervised multitask learning for sequence labeling (No. arXiv:1704.07156). arXiv. https://doi.org/10.48550/arXiv.1704.07156
